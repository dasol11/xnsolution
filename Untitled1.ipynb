{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from XNCmmLib import XNCmmUnit as Cmm\n",
    "import XNDatabaseLib as DbLib\n",
    "import os\n",
    "import joblib\n",
    "# NuralNet (Regression)\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__()  # nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1), node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2, hiddenlayer + 2):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer + 2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1 = nn.Sequential(ordered_dict)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        pred_x = self.layer1(X_test)\n",
    "\n",
    "        return pred_x\n",
    "\n",
    "    def fit(self, epochs, loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                return\n",
    "                # print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "\n",
    "class Regression:\n",
    "    def regressionexcute(trdataID, tsdataID, cols, fcols, hiddenlayer, node, Ouputnode, epochs):\n",
    "        # TrainingID의 cols열을 dataframe 변수\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(trdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        trdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "        # print(trdf)\n",
    "        # 예측하는 데이터열을 dataframe 변수\n",
    "        trfdf = Cmm.DfToCustomDf(df, Cmm.StrToList(fcols, ','))\n",
    "        # print(fdf)\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(tsdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        tsdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "        # print(tsdf)\n",
    "        tsfdf = Cmm.DfToCustomDf(df, Cmm.StrToList(fcols, ','))\n",
    "\n",
    "        # cbm 호출\n",
    "        a = Regression.RNet(trdf, trfdf, tsdf, tsfdf, hiddenlayer, node, Ouputnode, epochs)\n",
    "        jstr = Cmm.ClassToJson(a)\n",
    "\n",
    "        return jstr\n",
    "\n",
    "    def MAPE_regression(y_test, y_pred):\n",
    "        return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "\n",
    "    def RNet(X_train, y_train, X_test, y_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "        '''\n",
    "\n",
    "            @Input\n",
    "                X_train : type : array\n",
    "                y_train : type : array\n",
    "                X_test : type : array\n",
    "                hiddenlayer : type : int\n",
    "                node : type : int\n",
    "                Ouputnode : type : int\n",
    "                epochs : type : int\n",
    "\n",
    "            @Output\n",
    "                pred_y_test : type : array\n",
    "\n",
    "        '''\n",
    "\n",
    "        # 데이터를 파이토치 텐서로 변경\n",
    "        X = torch.Tensor(X_train.values)\n",
    "        Y = torch.Tensor(y_train.values)\n",
    "        X_test = torch.Tensor(X_test.values)\n",
    "\n",
    "        # 학습을 위한 데이터 전처리\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "        # 신경망 생성하기\n",
    "        model = RegressionNet(X, hiddenlayer, node, Ouputnode)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        model.fit(epochs, loader, criterion, optimizer)\n",
    "\n",
    "        # 학습되 모델 저장\n",
    "        modelfilename = Cmm.GetSaveModelName(\"RGNueralnet\")\n",
    "        modelpath = Cmm.GetSaveModelPath() + modelfilename\n",
    "        saveModel = joblib.dump(model, modelpath)\n",
    "        str64 = Cmm.FileToBase64(modelpath)\n",
    "\n",
    "        if os.path.exists(modelpath):\n",
    "            os.remove(modelpath)\n",
    "\n",
    "        # 테스트 데이터로 예측 결과 반환\n",
    "        pred_y_test = model.predict(X_test)\n",
    "\n",
    "        # 파이토치 텐서를 넘파이 어레이로 전환\n",
    "        pred_y_test = pred_y_test.detach().numpy()\n",
    "\n",
    "        MSE = mean_squared_error(y_test, pred_y_test)  # MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\n",
    "\n",
    "        # 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\n",
    "        RMSE = np.sqrt(MSE)\n",
    "        MAPE = Regression.MAPE_regression(y_test, pred_y_test)\n",
    "        R_squared = r2_score(y_test, pred_y_test)\n",
    "\n",
    "        lists = pred_y_test.tolist()\n",
    "        pred_y_testJson = Cmm.NumlistToOneValueArraystring(lists)\n",
    "\n",
    "\n",
    "        return {'Ypred': pred_y_testJson, 'Rmse': str(RMSE), 'Mape': str(float(MAPE)), \"Rsquared\": str(R_squared)}, {\"Modelfile\": str(modelfilename), \"Modelcontents\": str(str64)}\n",
    "\n",
    "#trdataid=20220707-0003-CS&tsdataid=20220707-0003-CT&cols=형폐시간,쿠션위치,보압절환위치,계량완료위치&fcols=공정시간&hiddenlayer=2&node=5&ouputnode=1&epochs=10\n",
    "#a = Regression.regressionexcute('20220707-0003-CS','20220707-0003-CT', '형폐시간,쿠션위치,보압절환위치,계량완료위치','보압절환압력',2,5,1,10)\n",
    "#print(a)\n",
    "\n",
    "\n",
    "# df2 = pd.read_csv(\"C:\\\\Regression\\\\RMS_bearing.csv\")\n",
    "# x1 = df2.iloc[:,[0,1,2]]\n",
    "# y1 = df2.iloc[:,[3]]\n",
    "# X1_train,X1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, random_state=33)\n",
    "# pred_y1_test = Regression.RNet(X1_train, y1_train, X1_test, y1_test, 2, 5, 1, 10)\n",
    "# print(pred_y1_test)\n",
    "# RNET = torch.load(\"RNet.pt\")\n",
    "# RNET.eval(\n",
    "# X1_test = torch.Tensor(X1_test.values)\n",
    "# pred_y_test = RNET.predict(X1_test)\n",
    "# print(pred_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08afff3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'XNCmmLib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mXNCmmLib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XNCmmUnit \u001b[38;5;28;01mas\u001b[39;00m Cmm\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mXNDatabaseLib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mDbLib\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix,f1_score,roc_curve\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'XNCmmLib'"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from XNCmmLib import XNCmmUnit as Cmm\n",
    "import XNDatabaseLib as DbLib\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix,f1_score,roc_curve\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# NuralNet (Classification)\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__()  # nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1), node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2, hiddenlayer + 2):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer + 2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1 = nn.Sequential(ordered_dict)\n",
    "        # print(self.layer1)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        pred_x = self.layer1(X_test)\n",
    "\n",
    "        return pred_x\n",
    "\n",
    "    def fit(self, epochs, loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                return\n",
    "            # print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "\n",
    "class Classification:\n",
    "    def cnetexcute(trdataID, tsdataID, cols, fcols, hiddenlayer, node, Ouputnode, epochs):\n",
    "        # TrainingID의 cols열을 dataframe 변수\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(trdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        trdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "        # print(trdf)\n",
    "        # 예측하는 데이터열을 dataframe 변수\n",
    "        trfdf = Cmm.DfToCustomDf(df, Cmm.StrToList(fcols, ','))\n",
    "        # print(trfdf)\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(tsdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        tsdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "        # print(tsdf)\n",
    "        tsfdf = Cmm.DfToCustomDf(df, Cmm.StrToList(fcols, ','))\n",
    "        # print(tsfdf)\n",
    "\n",
    "        # cnet 호출\n",
    "        a = Classification.CNet(trdf, trfdf, tsdf, tsfdf, hiddenlayer, node, Ouputnode, epochs)\n",
    "        jstr = Cmm.ClassToJson(a)\n",
    "\n",
    "        return jstr\n",
    "\n",
    "\n",
    "    def CNet(X_train, y_train, X_test, y_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "        '''\n",
    "\n",
    "            @Input\n",
    "                X_train : type : array\n",
    "                y_train : type : array\n",
    "                X_test : type : array\n",
    "                hiddenlayer : type : int\n",
    "                node : type : int\n",
    "                Ouputnode : type : int\n",
    "                epochs : type : int\n",
    "\n",
    "            @Output\n",
    "                pred_y_test : type : array\n",
    "\n",
    "        '''\n",
    "\n",
    "        # 데이터를 파이토치 텐서로 변경\n",
    "        X = torch.Tensor(X_train.values)\n",
    "        Y = torch.Tensor(y_train.values)\n",
    "        X_test = torch.Tensor(X_test.values)\n",
    "\n",
    "        # 학습을 위한 데이터 전처리\n",
    "        dataset = TensorDataset(X, Y)\n",
    "        loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "        # 신경망 생성하기\n",
    "        model = ClassificationNet(X, hiddenlayer, node, Ouputnode)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "        model.fit(epochs, loader, criterion, optimizer)\n",
    "\n",
    "        # 학습되 모델 저장\n",
    "        modelfilename = Cmm.GetSaveModelName(\"CFNeuralnet\")\n",
    "        modelpath = Cmm.GetSaveModelPath() + modelfilename\n",
    "        saveModel = joblib.dump(model, modelpath)\n",
    "        str64 = Cmm.FileToBase64(modelpath)\n",
    "\n",
    "        if os.path.exists(modelpath):\n",
    "            os.remove(modelpath)\n",
    "\n",
    "        # 테스트 데이터로 예측 결과 반환\n",
    "        pred_y_test = model.predict(X_test)\n",
    "\n",
    "        # 파이토치 텐서를 넘파이 어레이로 전환\n",
    "        pred_y_test = pred_y_test.detach().numpy()\n",
    "        predarray = Cmm.ListToOneValueArraystring(pred_y_test)\n",
    "\n",
    "        # pred_prob = pred_y_test\n",
    "        #\n",
    "        # fpr_array = np.array([], dtype=np.int32)\n",
    "        # tpr_array = np.array([], dtype=np.int32)\n",
    "        #\n",
    "        # for i in range(1, 100):\n",
    "        #     predd = np.array([], dtype=np.int32)\n",
    "        #     for j in range(len(pred_prob)):\n",
    "        #         decision_boundary = i / 100\n",
    "        #         if (pred_prob[j] > decision_boundary) == True:\n",
    "        #             predd = np.append(predd, 1)\n",
    "        #         else:\n",
    "        #             predd = np.append(predd, 0)\n",
    "        #\n",
    "        #     cofMatt = confusion_matrix(y_test, predd, labels=[1, 0])  # 1: 불량, 0: 정상\n",
    "        #     ##confusion matrix의 각 요소\n",
    "        #     tpp = cofMatt[1, 1]\n",
    "        #     tnn = cofMatt[0, 0]\n",
    "        #     fnn = cofMatt[1, 0]\n",
    "        #     fpp = cofMatt[0, 1]\n",
    "        #     tpr = tpp / (tpp + fnn)\n",
    "        #     fpr = fpp / (tnn + fpp)\n",
    "        #\n",
    "        #     fpr_array = np.append(fpr_array, fpr)\n",
    "        #     tpr_array = np.append(tpr_array, tpr)\n",
    "\n",
    "\n",
    "        # calculate AUC of model\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, pred_y_test)\n",
    "        auc = roc_auc_score(y_test, pred_y_test)\n",
    "\n",
    "        lists = fpr.tolist()\n",
    "        fprJson = Cmm.NumlistToArraystring(lists)\n",
    "        lists = tpr.tolist()\n",
    "        tprJson = Cmm.NumlistToArraystring(lists)\n",
    "\n",
    "        return ({\"Aucscore\": str(auc), \"Fpr\": fprJson, \"Tpr\": tprJson, \"Predarray\" :predarray}), {\"Modelfile\": str(modelfilename), \"Modelcontents\": str(str64)}\n",
    "\n",
    "# trdataid=20220707-0003-CS&tsdataid=20220707-0003-CT&cols=쿠션위치,보압절환위치,계량완료위치,형계위치,사출최대속도&fcols=불량판정&hiddenlayer=2&node=3&ouputnode=5&epochs=10\n",
    "# a = Classification.cnetexcute('20220707-0003-CS','20220707-0003-CT', '쿠션위치,보압절환위치,계량완료위치,형계위치,사출최대속도','불량판정',2,5,1,10)\n",
    "# print(a)\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\"C:\\\\Classfication\\\\ab_te.csv\")\n",
    "x = df1.iloc[:,[0, 1, 2, 3]]\n",
    "y = df1.iloc[:,[4]]\n",
    "X_train,X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=33)\n",
    "pred_y1_test = Classification.CNet(X_train, y_train, X_test,y_test, 2, 5, 1, 10)\n",
    "print(pred_y1_test)\n",
    "pred_y1_test\n",
    "\n",
    "# pred_y1_test['Fpr']\n",
    "# pred_y1_test['Tpr']\n",
    "\n",
    "\n",
    "\n",
    "CNET = torch.load(\"CNet.pt\")\n",
    "CNET.eval()\n",
    "X_test = torch.Tensor(X_test.values)\n",
    "pred_y_test = CNET.predict(X_test)\n",
    "print(pred_y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d496c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a67c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
