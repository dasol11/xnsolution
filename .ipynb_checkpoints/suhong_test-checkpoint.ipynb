{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5211dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import pickle\n",
    "from scipy import linalg # covaraince sclaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4a30c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_limit(stat, alpha=0.05, bootstrap=100, upper = True):\n",
    "    '''\n",
    "        @Description\n",
    "            Bootstrap sampling을 활용한 Control Limit 산출 기법\n",
    "\n",
    "        @Parameter\n",
    "            stat : 통계량 (정상상태의 데이터 입력)\n",
    "            alpha : Control Limit을 정하기 위한 유의수준 (0~1)\n",
    "            bootstrap : 샘플링 횟수\n",
    "        @Return\n",
    "            limit : 임계값 (CL : Control Limit)\n",
    "    '''\n",
    "    \n",
    "    alpha = alpha * 100\n",
    "    if(upper) : alpha = 100 - alpha\n",
    "    samsize = max(100, len(stat))\n",
    "    \n",
    "    stat = stat.reshape(len(stat)) # 2차원 array를 1차원 array로 변환\n",
    "    \n",
    "    # bootstrap 수 만큼 다음 작업을 반복 : samsize(최소 10000번)만큼 정상상태 데이터를 유의수준 만큼 복원 추출 후 평균 값 사용 \n",
    "    limit = np.mean(list(map(lambda x:np.percentile(np.random.choice(stat,samsize,replace=True),alpha), range(0,bootstrap))))\n",
    "    \n",
    "    return limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6615c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2norm(stat):\n",
    "    return(np.sqrt(stat**2))\n",
    "\n",
    "def matrix_inv(matrix):\n",
    "    return linalg.pinv(matrix,cond=1.490116e-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea9fec",
   "metadata": {},
   "source": [
    "class covariance_scaler() :\n",
    "    \n",
    "    def __init__(self) :\n",
    "        \n",
    "        self.cov_inv_matrix = None\n",
    "            \n",
    "    def fit(self, trdat):\n",
    "        \n",
    "        cov_mat = np.cov(trdat.transpose())\n",
    "        self.cov_inv_matrix = matrix_inv(cov_mat)\n",
    "        \n",
    "    def transform(self, tsdat) :\n",
    "        if isinstance(tsdat, list) :\n",
    "            tsdat = np.array(tsdat).transpose()\n",
    "            \n",
    "        scaled_residual = np.dot(np.array(tsdat), self.cov_inv_matrix)\n",
    "        return scaled_residual\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "009cded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_scaler(trdat, resi) :\n",
    "    \n",
    "    if isinstance(resi, list) :\n",
    "        resi = np.array(resi).transpose()\n",
    "        \n",
    "    cov_matrix = np.cov(trdat.transpose()) # trdat의 공분산행렬\n",
    "    cov_inv_matrix = matrix_inv(cov_matrix) # 공분산 행렬의 역행렬\n",
    "\n",
    "    scaled_residual = np.dot(np.array(resi), cov_inv_matrix) # 공분산 스케일된 결과\n",
    "    \n",
    "    return scaled_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f88af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSET Linear Regression\n",
    "def mset_regress(trdat, tsdat, alpha=0.05):\n",
    "    '''\n",
    "        @Description\n",
    "            MSET Linear Regression\n",
    "\n",
    "        @Parameter\n",
    "            trdat : 학습데이터\n",
    "            tsdat : 평가데이터\n",
    "            alpha : control limit의 유의수준\n",
    "\n",
    "        @Return\n",
    "            trScore : MSET Linear Regression의 Train 잔차 (이상감지 통계량)\n",
    "            tsScore : MSET Linear Regression의 Test 잔차 (이상감지 통계량)\n",
    "            varTrScore : 변수 별 이상감지 통계량\n",
    "            varTsScore : 변수 별 이상감지 통계량\n",
    "            UCL : control limit\n",
    "            LCL : control limit\n",
    "            varUCL : 변수 별 control limit\n",
    "            varLCL : 변수 별 control limit\n",
    "    '''\n",
    "\n",
    "    train_intercept = np.ones((trdat.shape[0], 1))\n",
    "    test_intercept = np.ones((tsdat.shape[0], 1))\n",
    "\n",
    "    # 초기값 선언\n",
    "    y_hat_tr = np.zeros((trdat.shape[0], trdat.shape[1]))\n",
    "    y_hat_ts = np.zeros((tsdat.shape[0], tsdat.shape[1]))\n",
    "\n",
    "    # Control limit\n",
    "    UCL = []\n",
    "    LCL = []\n",
    "    varUCL = []\n",
    "    varLCL = []\n",
    "\n",
    "    # train data, test data 학습 학습\n",
    "    for i in range(len(trdat.columns)):\n",
    "        # MSET 기반으로 학습시키기 위한 학습데이터 변환\n",
    "        trainX = np.concatenate((train_intercept, np.delete(trdat.values, i, axis=1)), axis=1)\n",
    "        trainY = trdat.values[:, i]\n",
    "        testX = np.concatenate((test_intercept, np.delete(tsdat.values, i, axis=1)), axis=1)\n",
    "\n",
    "        y_hat_tr[:, i] = trainX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "        y_hat_ts[:, i] = testX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "\n",
    "        # control limit (each variable)\n",
    "        varUCL.append(bootstrap_limit(trainY-y_hat_tr[:, i], alpha=alpha / 2))\n",
    "        varLCL.append(bootstrap_limit(trainY-y_hat_tr[:, i], alpha=alpha / 2, upper=False))\n",
    "\n",
    "    varTrScore = trdat.values - y_hat_tr\n",
    "    varTsScore = tsdat.values - y_hat_ts\n",
    "\n",
    "    # covariance scaled with anomaly sscore\n",
    "    trScore = L2norm(covariance_scaler(trdat, varTrScore)).sum(axis=1)\n",
    "    tsScore = L2norm(covariance_scaler(trdat, varTsScore)).sum(axis=1)\n",
    "\n",
    "    # control limit (UCL=LCL)\n",
    "    UCL = bootstrap_limit(trScore, alpha=alpha)\n",
    "    LCL = UCL\n",
    "\n",
    "\n",
    "    return {\"Trscore\": trScore, \"Tsscore\": tsScore, \"Vartrscore\": varTrScore, \"Vartsscore\": varTsScore, \"Ucl\": str(UCL),\n",
    "            \"Lcl\": str(LCL), \"Varucl\": varUCL, \"Varlcl\": varLCL}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fab5f1e",
   "metadata": {},
   "source": [
    "# MSET Linear Regression 양측검정\n",
    "def mset_regress(trdat, tsdat, alpha=0.05):\n",
    "    '''\n",
    "        @Description\n",
    "            MSET Linear Regression\n",
    "\n",
    "        @Parameter\n",
    "            trdat : 학습데이터\n",
    "            tsdat : 평가데이터\n",
    "            alpha : control limit의 유의수준\n",
    "\n",
    "        @Return\n",
    "            trScore : MSET Linear Regression의 Train 잔차 (이상감지 통계량)\n",
    "            tsScore : MSET Linear Regression의 Test 잔차 (이상감지 통계량)\n",
    "            CL : control limit (교수님과 회의 후 설정 예정)\n",
    "    '''   \n",
    "    \n",
    "    train_intercept = np.ones((trdat.shape[0],1))\n",
    "    test_intercept = np.ones((tsdat.shape[0],1))\n",
    "\n",
    "    # 초기값 선언\n",
    "    y_hat_tr = np.zeros((trdat.shape[0], trdat.shape[1]))\n",
    "    y_hat_ts = np.zeros((tsdat.shape[0], tsdat.shape[1]))\n",
    "         \n",
    "    # control limit 초기값\n",
    "    ucl = []\n",
    "    lcl = []\n",
    "    \n",
    "    # train data, test data 학습 학습\n",
    "    for i in range(len(trdat.columns)):\n",
    "        \n",
    "        # MSET 기반으로 학습시키기 위한 학습데이터 변환\n",
    "        trainX = np.concatenate((train_intercept, np.delete(trdat.values,i,axis=1)), axis=1)\n",
    "        trainY = trdat.values[:,i]\n",
    "        testX = np.concatenate((test_intercept, np.delete(tsdat.values,i,axis=1)), axis=1)\n",
    "        \n",
    "        y_hat_tr[:,i] = trainX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "        y_hat_ts[:,i] = testX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "        \n",
    "        res = trdat.values[:,i]-y_hat_tr[:,i]\n",
    "        ucl.append(bootstrap_limit(res, alpha=alpha/2))\n",
    "        lcl.append(bootstrap_limit(res, alpha=alpha/2, upper=False))\n",
    "        \n",
    "    residual_tr =  trdat.values - y_hat_tr\n",
    "    residual_ts =  tsdat.values - y_hat_ts\n",
    "                                                                                                   \n",
    "    return {\"trScore\" : residual_tr, \"tsScore\" : residual_ts, \"ucl\" : ucl, \"lcl\" : lcl}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68da2eef",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor # randomforest library\n",
    "from adFunction import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import XNDatabaseLib as DbLib\n",
    "from XNCmmLib import XNCmmUnit as Cmm\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import json\n",
    "\n",
    "class MSET:\n",
    "    def regressionexcute(trdataID, tsdataID, cols, alpha):\n",
    "        # TrdataID를 dataframe 변수\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(trdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        trdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "\n",
    "        # TsdataID를 dataframe 변수\n",
    "        txt = DbLib.DatabaseUnit.GetDataSet(tsdataID)\n",
    "        df = pd.read_csv(Cmm.StrToStringIO(txt), sep=',', encoding='utf-8-sig')\n",
    "        tsdf = Cmm.DfToCustomDf(df, Cmm.StrToList(cols, ','))\n",
    "\n",
    "        a = MSET.mset_regress(trdf,tsdf,alpha)\n",
    "\n",
    "        jstr = Cmm.ClassToJson(a)\n",
    "\n",
    "        return jstr\n",
    "\n",
    "    # MSET Linear Regression\n",
    "    def mset_regress(trdat, tsdat, alpha=0.05):\n",
    "        '''\n",
    "            @Description\n",
    "                MSET Linear Regression\n",
    "\n",
    "            @Parameter\n",
    "                trdat : 학습데이터\n",
    "                tsdat : 평가데이터\n",
    "                alpha : control limit의 유의수준\n",
    "\n",
    "            @Return\n",
    "                trScore : MSET Linear Regression의 Train 잔차 (이상감지 통계량)\n",
    "                tsScore : MSET Linear Regression의 Test 잔차 (이상감지 통계량)\n",
    "                varTrScore : 변수 별 이상감지 통계량\n",
    "                varTsScore : 변수 별 이상감지 통계량\n",
    "                UCL : control limit\n",
    "                LCL : control limit\n",
    "                varUCL : 변수 별 control limit\n",
    "                varLCL : 변수 별 control limit\n",
    "        '''\n",
    "\n",
    "        train_intercept = np.ones((trdat.shape[0], 1))\n",
    "        test_intercept = np.ones((tsdat.shape[0], 1))\n",
    "\n",
    "        # 초기값 선언\n",
    "        y_hat_tr = np.zeros((trdat.shape[0], trdat.shape[1]))\n",
    "        y_hat_ts = np.zeros((tsdat.shape[0], tsdat.shape[1]))\n",
    "\n",
    "        # Control limit\n",
    "        UCL = []\n",
    "        LCL = []\n",
    "        varUCL = []\n",
    "        varLCL = []\n",
    "\n",
    "        # train data, test data 학습 학습\n",
    "        for i in range(len(trdat.columns)):\n",
    "            # MSET 기반으로 학습시키기 위한 학습데이터 변환\n",
    "            trainX = np.concatenate((train_intercept, np.delete(trdat.values, i, axis=1)), axis=1)\n",
    "            trainY = trdat.values[:, i]\n",
    "            testX = np.concatenate((test_intercept, np.delete(tsdat.values, i, axis=1)), axis=1)\n",
    "\n",
    "            y_hat_tr[:, i] = trainX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "            y_hat_ts[:, i] = testX @ np.linalg.pinv(trainX.transpose() @ trainX) @ trainX.transpose() @ trainY\n",
    "\n",
    "            # control limit (each variable)\n",
    "            varUCL.append(bootstrap_limit(trainY-y_hat_tr[:, i], alpha=alpha / 2))\n",
    "            varLCL.append(bootstrap_limit(trainY-y_hat_tr[:, i], alpha=alpha / 2, upper=False))\n",
    "\n",
    "        varTrScore = trdat.values - y_hat_tr\n",
    "        varTsScore = tsdat.values - y_hat_ts\n",
    "\n",
    "        # covariance scaled with anomaly sscore\n",
    "        trScore = L2norm(covariance_scaler(trdat, varTrScore)).sum(axis=1)\n",
    "        tsScore = L2norm(covariance_scaler(trdat, varTsScore)).sum(axis=1)\n",
    "\n",
    "        # control limit (UCL=LCL)\n",
    "        UCL = bootstrap_limit(trScore, alpha=alpha)\n",
    "        LCL = UCL\n",
    "\n",
    "        lists = trScore.tolist()\n",
    "        trScoreJson = Cmm.NumlistToOneValueArraystring(lists)\n",
    "        lists = tsScore.tolist()\n",
    "        tsScoreJson = Cmm.NumlistToOneValueArraystring(lists)\n",
    "        lists = varTrScore.tolist()\n",
    "        varTrScoreJson = Cmm.NumlistToArraystring(lists)\n",
    "        lists = varTsScore.tolist()\n",
    "        varTsScoreJson = Cmm.NumlistToArraystring(lists)\n",
    "\n",
    "        return {\"Trscore\": trScoreJson, \"Tsscore\": tsScoreJson, \"Vartrscore\": varTrScoreJson, \"Vartsscore\": varTsScoreJson, \"Ucl\": str(UCL),\n",
    "                \"Lcl\": str(LCL), \"Varucl\": varUCL, \"Varlcl\": varLCL}\n",
    "\n",
    "a = MSET.regressionexcute(\"20220707-0003-CS\",\"20220707-0003-CT\",\"사출최대압력,보압절환압력\",0.05)\n",
    "print(a)\n",
    "\n",
    "\n",
    "# print(type(np.transpose(resi)))\n",
    "# print(type(ucl))\n",
    "# print(type(lcl)\n",
    "# ScoreJson = json.dumps(np.transpose(resi))\n",
    "# uclJson = json.dumps(ucl)\n",
    "# lclJson = json.dumps(lcl)\n",
    "\n",
    "# # 예제\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from test import *\n",
    "# df = pd.read_csv(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\test_data.csv\", encoding='euc-kr')\n",
    "#\n",
    "# # MSET Linear Regression\n",
    "# trdat = df[0:500]\n",
    "# tsdat = df[500:1000]\n",
    "#\n",
    "# model = mset_regress(trdat, tsdat, alpha=0.005)\n",
    "# plt.figure(figsize=(12,4))\n",
    "# plt.plot(model['varTsScore'][:,2], color='blue')\n",
    "# plt.axhline(y=model['varUCL'][2], color='red')\n",
    "# plt.axhline(y=model['varLCL'][2], color='red')\n",
    "# plt.show()\n",
    "#\n",
    "# msetreg = mset_regress(trdat, tsdat, alpha=0.05)\n",
    "# msetrf = mset_randomforest(trdat, tsdat, alpha=0.01, ntree=100)\n",
    "#\n",
    "# print(msetreg['tsScore'])\n",
    "# print(msetrf['tsScore'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
