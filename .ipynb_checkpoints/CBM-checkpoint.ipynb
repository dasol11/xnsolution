{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thur Jul  7 16:20:39 2022\n",
    "Revised on Thur Jul  13 15:20:39 2022\n",
    "\n",
    "@author: Junhyun\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "\n",
    "def bootstrap_limit(stat, alpha=0.05, bootstrap=100):\n",
    "    '''\n",
    "        @Description\n",
    "            Bootstrap sampling을 활용한 Control Limit 산출 기법\n",
    "\n",
    "        @Parameter\n",
    "            stat : 통계량 (정상상태의 데이터 입력)\n",
    "            alpha : Control Limit을 정하기 위한 유의수준 (0~1)\n",
    "            bootstrap : 샘플링 횟수\n",
    "        @Return\n",
    "            limit : 임계값 (CL : Control Limit)\n",
    "    '''\n",
    "    alpha = alpha*100\n",
    "    alpha = 100 - alpha\n",
    "    samsize = max(100, len(stat))\n",
    "    \n",
    "    stat = stat.reshape(len(stat)) # 2차원 array를 1차원 array로 변환\n",
    "    \n",
    "    # bootstrap 수 만큼 다음 작업을 반복 : samsize(최소 10000번)만큼 정상상태 데이터를 유의수준 만큼 복원 추출 후 평균 값 사용 \n",
    "    limit = np.mean(list(map(lambda x:np.percentile(np.random.choice(stat,samsize,replace=True),alpha), range(0,bootstrap))))\n",
    "    \n",
    "    return limit\n",
    "\n",
    "class CBM():\n",
    "    \"\"\"\n",
    "    CBM : Clustering Base Mahalanobis distance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.tr_k_mu = None\n",
    "        self.tr_k_cov = None\n",
    "        self.cl = None\n",
    "        self.n_clusters = None\n",
    "        \n",
    "    def fit(self, trdat, n_clusters=3, max_iter=100, alpha=0.05):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        trdat : array\n",
    "            Train data\n",
    "        n_clusters : int\n",
    "            cluster의 수\n",
    "        max_iter : int\n",
    "            kmeans clustering 학습 횟수        \n",
    "        alpha : int, 0~1\n",
    "            Bootstrap Limit value. The default is 0.05.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        trScore : array\n",
    "            Train Score, 이상치 점수를 의미함. 클수록 정상패턴에서 벗어남을 의미\n",
    "        CL : float\n",
    "            trScore Control Limit\n",
    "\n",
    "        \"\"\"\n",
    "        '''\n",
    "        km = KMeans(n_clusters=n_clusters,max_iter=max_iter,random_state=0).fit(trdat)\n",
    "        km_score = km.predict(trdat)\n",
    "        cluster_df = pd.concat([pd.DataFrame(trdat),pd.DataFrame(km_score, columns=['cluster'])], axis=1)\n",
    "\n",
    "        # 실제 사용할 클러스터 개수 (클러스터 내 관측치가 한개인 데이터 제거)\n",
    "        cluster_cnt = np.unique(km_score, return_counts = True)[1]\n",
    "        ClusterId = np.where(cluster_cnt!=1)[0]\n",
    "\n",
    "        cluster_df = cluster_df[cluster_df['cluster'].isin(ClusterId)]\n",
    "        '''\n",
    "        \n",
    "        if isinstance(trdat,(np.ndarray)):\n",
    "            trdat = pd.DataFrame(trdat)\n",
    "            \n",
    "        km = KMeans(n_clusters=n_clusters,max_iter=max_iter,random_state=0).fit(trdat)\n",
    "        km_score = km.predict(trdat)\n",
    "        cluster_df = pd.concat([pd.DataFrame(trdat),pd.DataFrame(km_score, columns=['cluster'])], axis=1)\n",
    "        \n",
    "        # kmeans 예외처리\n",
    "        cluster_cnt = np.unique(km_score, return_counts = True)[1]\n",
    "        ClusterId = np.where(cluster_cnt!=1)[0]\n",
    "        cluster_df = cluster_df[cluster_df['cluster'].isin(ClusterId)].reset_index(drop=True)\n",
    "        \n",
    "        self.tr_k_mu = np.zeros((trdat.shape[1], len(ClusterId)))\n",
    "        self.tr_k_cov = np.zeros((len(ClusterId), trdat.shape[1], trdat.shape[1]))\n",
    "        self.n_clusters = len(ClusterId)\n",
    "        \n",
    "        \n",
    "        for i in range(len(ClusterId)):\n",
    "            \n",
    "            self.tr_k_mu[:,i] = cluster_df.drop('cluster', axis=1)[cluster_df['cluster'] == ClusterId[i]].mean()\n",
    "            self.tr_k_cov[i] = cluster_df.drop('cluster', axis=1)[cluster_df['cluster'] == ClusterId[i]].cov()\n",
    "\n",
    "        trCbmMat = np.zeros((len(trdat), self.n_clusters))\n",
    "        \n",
    "        # train fit\n",
    "        for i in range(len(trdat)):\n",
    "            for j in range(self.n_clusters):\n",
    "                # cluster 별 마할라노비스 계산\n",
    "                trCbmMat[i,j] = (trdat.values[i,:] - self.tr_k_mu[:,j]) @ np.linalg.pinv(self.tr_k_cov[j]) @ (trdat.values[i,:] - self.tr_k_mu[:,j]).transpose()\n",
    "        \n",
    "        # CBM 이상감지 통계량\n",
    "        self.trScore = trCbmMat.min(axis=1)\n",
    "        self.cl = bootstrap_limit(self.trScore, alpha=alpha, bootstrap=100)\n",
    "        \n",
    "        return {\"trScore\" : self.trScore}\n",
    "    \n",
    "    def CL_printor(self) :\n",
    "        \"\"\"\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        CL: float\n",
    "            Control Limit,\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        return {'CL' : self.cl}\n",
    "    \n",
    "    def predict(self, tsdat):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        tsdat : array\n",
    "            Test data. 예측 대상이 되는 데이터\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tsScore : array\n",
    "            Test data의 이상치 값\n",
    "\n",
    "        \"\"\"\n",
    "        if isinstance(tsdat,(np.ndarray)):\n",
    "            tsdat = pd.DataFrame(tsdat)\n",
    "\n",
    "        tsCbmMat = np.zeros((len(tsdat), self.n_clusters))     \n",
    "        \n",
    "        # test fit\n",
    "        for i in range(len(tsdat)):\n",
    "            for j in range(self.n_clusters):\n",
    "                # cluster 별 마할라노비스 계산\n",
    "                tsCbmMat[i,j] = (tsdat.values[i,:] - self.tr_k_mu[:,j]) @ np.linalg.pinv(self.tr_k_cov[j]) @ (tsdat.values[i,:] - self.tr_k_mu[:,j]).transpose()\n",
    "    \n",
    "        # CBM 이상감지 통계량\n",
    "        tsScore = tsCbmMat.min(axis=1)\n",
    "    \n",
    "        return {\"tsScore\" : tsScore}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbm(trdat, tsdat, n_clusters=3, alpha=0.05):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trdat : array\n",
    "        Train data. 학습 대상이 되는 데이터\n",
    "    tsdat : array\n",
    "        Test data. 예측 대상이 되는 데이터\n",
    "    n_clusters : int\n",
    "        클러스터의 개수\n",
    "    alpha : float, 0~1\n",
    "            Bootstrap Limit value. The default is 0.05.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trScore : array\n",
    "        Train data의 이상치 값\n",
    "    tsScore : array\n",
    "        Test data의 이상치 값\n",
    "    CL : float \n",
    "        Control Limit\n",
    "\n",
    "    \"\"\"\n",
    "    model = CBM()\n",
    "    fit = model.fit(trdat, n_clusters=n_clusters, max_iter=100, alpha=alpha)\n",
    "    CL = model.CL_printor()\n",
    "    pred = model.predict(tsdat)\n",
    "    \n",
    "     # CBM model pickle 파일로 저장\n",
    "    saved_model = joblib.dump(model, 'cbm.pkl')\n",
    "    \n",
    "    return {'trScore':fit['trScore'], 'tsScore':pred['tsScore'], 'CL': CL['CL']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Model load\n",
    "import joblib\n",
    "def CBM_model_loader(pickleFile, tsdat) :\n",
    "    \"\"\"\n",
    "    저장한 모델을 로드한 후, 로드한 모델과 데이터를 활용해 분석 결과 리턴\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : ?\n",
    "        로드한 모델\n",
    "    tsdat : array\n",
    "        예측 데이터\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    모델 리턴과 동일\n",
    "\n",
    "    \"\"\"\n",
    "    model = joblib.load(pickleFile)  \n",
    "    CL = model.CL_printor()\n",
    "    pred = model.predict(tsdat)\n",
    "\n",
    "    return {'tsScore' : pred['tsScore'], 'CL' : CL['CL']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('test_data.csv', encoding='euc-kr')\n",
    "\n",
    "trdat = df.values[0:600,:]\n",
    "tsdat = df.values[600:891, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 14\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbm(trdat, tsdat, n_clusters=14, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
