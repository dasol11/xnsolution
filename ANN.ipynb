{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55fc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1987f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE_regression(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea16fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "                \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d62eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        print(self.layer1)\n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b25f3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNet(X_train, y_train, X_test,y_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    #신경망 생성하기\n",
    "    model = ClassificationNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "    \n",
    "    \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"CNet.pt\")\n",
    "    \n",
    "    pred_y_test = model.predict(X_test)\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "      # calculate AUC of model\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_y_test)\n",
    "    auc = roc_auc_score(y_test, pred_y_test)\n",
    "      \n",
    "    return  ({\"auc_score\": auc, \"fpr\":fpr, \"tpr\":tpr})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c71270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNet(X_train, y_train, X_test, y_test , hiddenlayer, node, Ouputnode, epochs):\n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 신경망 생성하기\n",
    "    model = RegressionNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "            \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"RNet.pt\")\n",
    "    \n",
    "    pred_y_test = model.predict(X_test)\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "    MSE = mean_squared_error(y_test, pred_y_test)  # MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\n",
    "    \n",
    "    # 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAPE = MAPE_regression(y_test, pred_y_test)\n",
    "    R_squared = r2_score(y_test, pred_y_test)\n",
    "    return {'pred_y' : pred_y_test, 'RMSE' : RMSE, 'MAPE' : MAPE, \"R_squared\" : R_squared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08163130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ab_te.csv\")\n",
    "df2 = pd.read_csv(\"RMS_bearing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53543fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.iloc[:,[0, 1, 2, 3]]\n",
    "y = df1.iloc[:,[4]]\n",
    "x1 = df2.iloc[:,[0,1,2]]\n",
    "y1 = df2.iloc[:,[3]]\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=33)\n",
    "\n",
    "X1_train,X1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8308379",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CNet() missing 1 required positional argument: 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_y_test \u001b[38;5;241m=\u001b[39m \u001b[43mCNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: CNet() missing 1 required positional argument: 'epochs'"
     ]
    }
   ],
   "source": [
    "pred_y_test = CNet(X_train, y_train, X_test, 2, 5, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d7dde1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0555],\n",
      "        [0.0562],\n",
      "        [0.0568],\n",
      "        [0.0699],\n",
      "        [0.0684],\n",
      "        [0.0575],\n",
      "        [0.0563],\n",
      "        [0.0556],\n",
      "        [0.0707],\n",
      "        [0.0575],\n",
      "        [0.0557],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0560],\n",
      "        [0.0564],\n",
      "        [0.0560],\n",
      "        [0.0616],\n",
      "        [0.0563],\n",
      "        [0.0609],\n",
      "        [0.0655],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0558],\n",
      "        [0.0574],\n",
      "        [0.0590],\n",
      "        [0.0561],\n",
      "        [0.0558],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0602],\n",
      "        [0.0586],\n",
      "        [0.0565],\n",
      "        [0.0714],\n",
      "        [0.0250],\n",
      "        [0.0621],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0622],\n",
      "        [0.0564],\n",
      "        [0.0558],\n",
      "        [0.0661],\n",
      "        [0.0560],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0562],\n",
      "        [0.0616],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0611],\n",
      "        [0.0588],\n",
      "        [0.0597],\n",
      "        [0.0587],\n",
      "        [0.0557],\n",
      "        [0.0668],\n",
      "        [0.0705],\n",
      "        [0.0558],\n",
      "        [0.0573],\n",
      "        [0.0561],\n",
      "        [0.0745],\n",
      "        [0.0768],\n",
      "        [0.0601],\n",
      "        [0.0560],\n",
      "        [0.0598],\n",
      "        [0.0557],\n",
      "        [0.0720],\n",
      "        [0.0559],\n",
      "        [0.0626],\n",
      "        [0.0771],\n",
      "        [0.0566],\n",
      "        [0.0556],\n",
      "        [0.0563],\n",
      "        [0.0673],\n",
      "        [0.0694],\n",
      "        [0.0559],\n",
      "        [0.0552],\n",
      "        [0.0611],\n",
      "        [0.0566],\n",
      "        [0.0555],\n",
      "        [0.0597],\n",
      "        [0.0661],\n",
      "        [0.0701],\n",
      "        [0.0557],\n",
      "        [0.0557],\n",
      "        [0.0820],\n",
      "        [0.0683],\n",
      "        [0.0570],\n",
      "        [0.0873],\n",
      "        [0.0562],\n",
      "        [0.0565],\n",
      "        [0.0558],\n",
      "        [0.0551],\n",
      "        [0.0692],\n",
      "        [0.0561],\n",
      "        [0.0598],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0554],\n",
      "        [0.0565],\n",
      "        [0.0615],\n",
      "        [0.0562],\n",
      "        [0.0560],\n",
      "        [0.0584],\n",
      "        [0.0697],\n",
      "        [0.0615],\n",
      "        [0.0632],\n",
      "        [0.0605],\n",
      "        [0.0600],\n",
      "        [0.0556],\n",
      "        [0.0785],\n",
      "        [0.0560],\n",
      "        [0.0795],\n",
      "        [0.0585],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0685],\n",
      "        [0.0554],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.0555],\n",
      "        [0.0919],\n",
      "        [0.0559],\n",
      "        [0.0712],\n",
      "        [0.0555],\n",
      "        [0.0554],\n",
      "        [0.0641],\n",
      "        [0.0627],\n",
      "        [0.0558],\n",
      "        [0.0556],\n",
      "        [0.0558],\n",
      "        [0.0559],\n",
      "        [0.0563],\n",
      "        [0.1138],\n",
      "        [0.0587],\n",
      "        [0.0579],\n",
      "        [0.0557],\n",
      "        [0.0706],\n",
      "        [0.0569],\n",
      "        [0.0557],\n",
      "        [0.0559],\n",
      "        [0.0558],\n",
      "        [0.0555],\n",
      "        [0.0559],\n",
      "        [0.0697],\n",
      "        [0.0564],\n",
      "        [0.0566],\n",
      "        [0.0558],\n",
      "        [0.0663],\n",
      "        [0.0555],\n",
      "        [0.0569],\n",
      "        [0.0553],\n",
      "        [0.0565],\n",
      "        [0.0815],\n",
      "        [0.0556],\n",
      "        [0.0766],\n",
      "        [0.0600],\n",
      "        [0.0701],\n",
      "        [0.0712],\n",
      "        [0.0561],\n",
      "        [0.0565],\n",
      "        [0.0686],\n",
      "        [0.0681],\n",
      "        [0.0556],\n",
      "        [0.0715],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.1097],\n",
      "        [0.0607],\n",
      "        [0.0586],\n",
      "        [0.0564],\n",
      "        [0.0555],\n",
      "        [0.0561],\n",
      "        [0.0654],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0608],\n",
      "        [0.0563],\n",
      "        [0.0565],\n",
      "        [0.0563],\n",
      "        [0.0860],\n",
      "        [0.0595],\n",
      "        [0.1062],\n",
      "        [0.0557],\n",
      "        [0.0561],\n",
      "        [0.0786],\n",
      "        [0.0562],\n",
      "        [0.0561],\n",
      "        [0.0796],\n",
      "        [0.0656],\n",
      "        [0.0568],\n",
      "        [0.0564],\n",
      "        [0.0557],\n",
      "        [0.0587],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0561]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18d5423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch // loss =4.4145748688606545e-05\n"
     ]
    }
   ],
   "source": [
    "pred_y1_test = RNet(X1_train, y1_train, X1_test, y1_test, 2, 5, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e177169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_y': array([[0.05581951],\n",
      "       [0.05592843],\n",
      "       [0.05608294],\n",
      "       [0.07431081],\n",
      "       [0.07184236],\n",
      "       [0.05623445],\n",
      "       [0.05595271],\n",
      "       [0.05586625],\n",
      "       [0.07511216],\n",
      "       [0.05623949],\n",
      "       [0.05590985],\n",
      "       [0.05591749],\n",
      "       [0.05585973],\n",
      "       [0.055989  ],\n",
      "       [0.05595178],\n",
      "       [0.05601093],\n",
      "       [0.05595222],\n",
      "       [0.06075853],\n",
      "       [0.05597548],\n",
      "       [0.05934162],\n",
      "       [0.06670599],\n",
      "       [0.05590209],\n",
      "       [0.05595299],\n",
      "       [0.05591214],\n",
      "       [0.05622137],\n",
      "       [0.0570599 ],\n",
      "       [0.05592656],\n",
      "       [0.05591507],\n",
      "       [0.05592405],\n",
      "       [0.05607687],\n",
      "       [0.05933477],\n",
      "       [0.05641753],\n",
      "       [0.05597213],\n",
      "       [0.0757955 ],\n",
      "       [0.05252802],\n",
      "       [0.06093362],\n",
      "       [0.05591894],\n",
      "       [0.05603671],\n",
      "       [0.06134077],\n",
      "       [0.05599769],\n",
      "       [0.05593308],\n",
      "       [0.06832883],\n",
      "       [0.05590633],\n",
      "       [0.05589351],\n",
      "       [0.05591362],\n",
      "       [0.05596592],\n",
      "       [0.06033972],\n",
      "       [0.05595474],\n",
      "       [0.05599097],\n",
      "       [0.05919795],\n",
      "       [0.05641209],\n",
      "       [0.05820999],\n",
      "       [0.05642166],\n",
      "       [0.0558948 ],\n",
      "       [0.06924465],\n",
      "       [0.07527684],\n",
      "       [0.0559296 ],\n",
      "       [0.05621141],\n",
      "       [0.05592533],\n",
      "       [0.07897748],\n",
      "       [0.0827899 ],\n",
      "       [0.05893594],\n",
      "       [0.05594114],\n",
      "       [0.05824049],\n",
      "       [0.05588821],\n",
      "       [0.07699545],\n",
      "       [0.05593545],\n",
      "       [0.0625216 ],\n",
      "       [0.08376803],\n",
      "       [0.05596867],\n",
      "       [0.05589987],\n",
      "       [0.05597527],\n",
      "       [0.07020564],\n",
      "       [0.07259026],\n",
      "       [0.05592391],\n",
      "       [0.05584461],\n",
      "       [0.05969714],\n",
      "       [0.05600007],\n",
      "       [0.05587912],\n",
      "       [0.05804868],\n",
      "       [0.0663183 ],\n",
      "       [0.07424958],\n",
      "       [0.05588771],\n",
      "       [0.05588084],\n",
      "       [0.08910871],\n",
      "       [0.07106942],\n",
      "       [0.05610793],\n",
      "       [0.09968656],\n",
      "       [0.05594171],\n",
      "       [0.05598341],\n",
      "       [0.05589516],\n",
      "       [0.05584759],\n",
      "       [0.07178803],\n",
      "       [0.05592233],\n",
      "       [0.05808565],\n",
      "       [0.05592938],\n",
      "       [0.05603222],\n",
      "       [0.05587598],\n",
      "       [0.05602161],\n",
      "       [0.0603671 ],\n",
      "       [0.05593418],\n",
      "       [0.05590471],\n",
      "       [0.05640957],\n",
      "       [0.07289988],\n",
      "       [0.06052459],\n",
      "       [0.06313074],\n",
      "       [0.05896216],\n",
      "       [0.05878195],\n",
      "       [0.05588308],\n",
      "       [0.08569801],\n",
      "       [0.05591466],\n",
      "       [0.08729453],\n",
      "       [0.05638272],\n",
      "       [0.05585146],\n",
      "       [0.05590858],\n",
      "       [0.07137743],\n",
      "       [0.05587164],\n",
      "       [0.05589634],\n",
      "       [0.05592445],\n",
      "       [0.05586421],\n",
      "       [0.10187179],\n",
      "       [0.05589596],\n",
      "       [0.07623135],\n",
      "       [0.05588312],\n",
      "       [0.05585491],\n",
      "       [0.06416931],\n",
      "       [0.06254062],\n",
      "       [0.05589842],\n",
      "       [0.05589153],\n",
      "       [0.05586201],\n",
      "       [0.05591898],\n",
      "       [0.0559448 ],\n",
      "       [0.13771963],\n",
      "       [0.0564114 ],\n",
      "       [0.05628724],\n",
      "       [0.05588666],\n",
      "       [0.07412216],\n",
      "       [0.05615291],\n",
      "       [0.05589258],\n",
      "       [0.0559461 ],\n",
      "       [0.05591626],\n",
      "       [0.0558713 ],\n",
      "       [0.05588136],\n",
      "       [0.07355385],\n",
      "       [0.05595917],\n",
      "       [0.05600702],\n",
      "       [0.05591165],\n",
      "       [0.06838585],\n",
      "       [0.05586446],\n",
      "       [0.05611468],\n",
      "       [0.05586929],\n",
      "       [0.05597855],\n",
      "       [0.09145392],\n",
      "       [0.0558963 ],\n",
      "       [0.08279829],\n",
      "       [0.05868883],\n",
      "       [0.07288103],\n",
      "       [0.07655957],\n",
      "       [0.05594508],\n",
      "       [0.05598313],\n",
      "       [0.07208213],\n",
      "       [0.07056784],\n",
      "       [0.05586574],\n",
      "       [0.07667157],\n",
      "       [0.05593463],\n",
      "       [0.0559078 ],\n",
      "       [0.13497514],\n",
      "       [0.05857334],\n",
      "       [0.05637521],\n",
      "       [0.05597434],\n",
      "       [0.05586117],\n",
      "       [0.05592058],\n",
      "       [0.06671431],\n",
      "       [0.05584459],\n",
      "       [0.05594805],\n",
      "       [0.0559578 ],\n",
      "       [0.05863507],\n",
      "       [0.05595755],\n",
      "       [0.0560086 ],\n",
      "       [0.0560245 ],\n",
      "       [0.09882239],\n",
      "       [0.05798879],\n",
      "       [0.12440024],\n",
      "       [0.05589148],\n",
      "       [0.05597363],\n",
      "       [0.08606286],\n",
      "       [0.05591803],\n",
      "       [0.05591964],\n",
      "       [0.08693092],\n",
      "       [0.06646925],\n",
      "       [0.05603796],\n",
      "       [0.05596431],\n",
      "       [0.05588036],\n",
      "       [0.05656454],\n",
      "       [0.05595642],\n",
      "       [0.05597598],\n",
      "       [0.05599255]], dtype=float32), 'RMSE': 0.005489003810928714, 'MAPE': ch4    15.161103\n",
      "dtype: float64, 'R_squared': 0.7612539928452167}\n"
     ]
    }
   ],
   "source": [
    "print(pred_y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8551fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=3, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNET = torch.load(\"RNet.pt\")\n",
    "RNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c155a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNET = torch.load(\"CNet.pt\")\n",
    "CNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0326758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1013],\n",
      "        [-0.1066],\n",
      "        [-0.0729],\n",
      "        [-0.0628],\n",
      "        [-0.1021],\n",
      "        [-0.0902],\n",
      "        [-0.0893],\n",
      "        [-0.1044],\n",
      "        [-0.0548],\n",
      "        [-0.0786],\n",
      "        [-0.0996],\n",
      "        [-0.0758],\n",
      "        [-0.0576],\n",
      "        [-0.0892],\n",
      "        [-0.1011],\n",
      "        [-0.0693],\n",
      "        [-0.0749],\n",
      "        [-0.0762],\n",
      "        [-0.1049],\n",
      "        [-0.0645],\n",
      "        [-0.0915],\n",
      "        [-0.0816],\n",
      "        [-0.0663],\n",
      "        [-0.0922],\n",
      "        [-0.0608],\n",
      "        [-0.0853],\n",
      "        [-0.0695],\n",
      "        [-0.0698],\n",
      "        [-0.0787],\n",
      "        [-0.0999],\n",
      "        [-0.0945],\n",
      "        [-0.0626],\n",
      "        [-0.0829],\n",
      "        [-0.0840],\n",
      "        [-0.0659],\n",
      "        [-0.0735],\n",
      "        [-0.0968],\n",
      "        [-0.0650],\n",
      "        [-0.1009],\n",
      "        [-0.0986],\n",
      "        [-0.0753],\n",
      "        [-0.0589],\n",
      "        [-0.0964],\n",
      "        [-0.0725],\n",
      "        [-0.0634],\n",
      "        [-0.0694],\n",
      "        [-0.0702],\n",
      "        [-0.0725],\n",
      "        [-0.0662],\n",
      "        [-0.0904],\n",
      "        [-0.0758],\n",
      "        [-0.0726],\n",
      "        [-0.1124],\n",
      "        [-0.0676],\n",
      "        [-0.0878],\n",
      "        [-0.0773],\n",
      "        [-0.0642],\n",
      "        [-0.0843],\n",
      "        [-0.0617],\n",
      "        [-0.0685],\n",
      "        [-0.0986],\n",
      "        [-0.0802],\n",
      "        [-0.1079],\n",
      "        [-0.0703],\n",
      "        [-0.0776],\n",
      "        [-0.0652],\n",
      "        [-0.0616],\n",
      "        [-0.0980],\n",
      "        [-0.0778],\n",
      "        [-0.0929],\n",
      "        [-0.0711],\n",
      "        [-0.0713],\n",
      "        [-0.1026],\n",
      "        [-0.0590],\n",
      "        [-0.0690],\n",
      "        [-0.1003],\n",
      "        [-0.0706],\n",
      "        [-0.0704],\n",
      "        [-0.0930],\n",
      "        [-0.0877],\n",
      "        [-0.0705],\n",
      "        [-0.0714],\n",
      "        [-0.0756],\n",
      "        [-0.0749],\n",
      "        [-0.0810],\n",
      "        [-0.0813],\n",
      "        [-0.0705],\n",
      "        [-0.1062],\n",
      "        [-0.0765],\n",
      "        [-0.1071],\n",
      "        [-0.0916],\n",
      "        [-0.0690],\n",
      "        [-0.0798],\n",
      "        [-0.1033],\n",
      "        [-0.0862],\n",
      "        [-0.0868],\n",
      "        [-0.1039],\n",
      "        [-0.0903],\n",
      "        [-0.0674],\n",
      "        [-0.0764],\n",
      "        [-0.0893],\n",
      "        [-0.0764],\n",
      "        [-0.0923],\n",
      "        [-0.0871],\n",
      "        [-0.0650],\n",
      "        [-0.0721],\n",
      "        [-0.0851],\n",
      "        [-0.0789],\n",
      "        [-0.0826],\n",
      "        [-0.1046],\n",
      "        [-0.0688],\n",
      "        [-0.0899],\n",
      "        [-0.0756],\n",
      "        [-0.1042],\n",
      "        [-0.0643],\n",
      "        [-0.0772],\n",
      "        [-0.0817],\n",
      "        [-0.0841],\n",
      "        [-0.0751],\n",
      "        [-0.1023],\n",
      "        [-0.0613],\n",
      "        [-0.0828],\n",
      "        [-0.0912],\n",
      "        [-0.0842],\n",
      "        [-0.1049],\n",
      "        [-0.0815],\n",
      "        [-0.1044],\n",
      "        [-0.0946],\n",
      "        [-0.0712],\n",
      "        [-0.0607],\n",
      "        [-0.1024],\n",
      "        [-0.0911],\n",
      "        [-0.0871],\n",
      "        [-0.0829],\n",
      "        [-0.0638],\n",
      "        [-0.0749],\n",
      "        [-0.0714],\n",
      "        [-0.0762],\n",
      "        [-0.0971],\n",
      "        [-0.0959],\n",
      "        [-0.0844],\n",
      "        [-0.0919],\n",
      "        [-0.0655],\n",
      "        [-0.0751],\n",
      "        [-0.1046],\n",
      "        [-0.0859],\n",
      "        [-0.0919],\n",
      "        [-0.1055],\n",
      "        [-0.0728],\n",
      "        [-0.1096],\n",
      "        [-0.0673],\n",
      "        [-0.0841],\n",
      "        [-0.0836],\n",
      "        [-0.0790],\n",
      "        [-0.1064],\n",
      "        [-0.0889],\n",
      "        [-0.0787],\n",
      "        [-0.0655],\n",
      "        [-0.0709],\n",
      "        [-0.0612],\n",
      "        [-0.1050],\n",
      "        [-0.1054],\n",
      "        [-0.1039],\n",
      "        [-0.0754],\n",
      "        [-0.0704],\n",
      "        [-0.1135],\n",
      "        [-0.0724],\n",
      "        [-0.0736],\n",
      "        [-0.0727],\n",
      "        [-0.0975],\n",
      "        [-0.0815],\n",
      "        [-0.1091],\n",
      "        [-0.0639],\n",
      "        [-0.1014],\n",
      "        [-0.0801],\n",
      "        [-0.1020],\n",
      "        [-0.0732],\n",
      "        [-0.0699],\n",
      "        [-0.0553],\n",
      "        [-0.0990],\n",
      "        [-0.1019],\n",
      "        [-0.0767],\n",
      "        [-0.0722],\n",
      "        [-0.0741],\n",
      "        [-0.0872],\n",
      "        [-0.0837],\n",
      "        [-0.0743],\n",
      "        [-0.0918],\n",
      "        [-0.0690],\n",
      "        [-0.0637],\n",
      "        [-0.0822],\n",
      "        [-0.0839],\n",
      "        [-0.0729],\n",
      "        [-0.0686],\n",
      "        [-0.0952],\n",
      "        [-0.0974],\n",
      "        [-0.0970],\n",
      "        [-0.0673],\n",
      "        [-0.0998],\n",
      "        [-0.1001],\n",
      "        [-0.0764],\n",
      "        [-0.0865],\n",
      "        [-0.0770],\n",
      "        [-0.0969],\n",
      "        [-0.1017],\n",
      "        [-0.0868],\n",
      "        [-0.0454],\n",
      "        [-0.0788],\n",
      "        [-0.0594],\n",
      "        [-0.1080],\n",
      "        [-0.1045],\n",
      "        [-0.0699],\n",
      "        [-0.0695],\n",
      "        [-0.0818],\n",
      "        [-0.0452],\n",
      "        [-0.0805],\n",
      "        [-0.0948],\n",
      "        [-0.0621],\n",
      "        [-0.0924],\n",
      "        [-0.1041],\n",
      "        [-0.0799],\n",
      "        [-0.0887],\n",
      "        [-0.0918],\n",
      "        [-0.0833],\n",
      "        [-0.0689],\n",
      "        [-0.0635],\n",
      "        [-0.0645],\n",
      "        [-0.0771],\n",
      "        [-0.0643],\n",
      "        [-0.0808],\n",
      "        [-0.0820],\n",
      "        [-0.1042],\n",
      "        [-0.0861],\n",
      "        [-0.0755],\n",
      "        [-0.0812],\n",
      "        [-0.1005],\n",
      "        [-0.0709],\n",
      "        [-0.0617],\n",
      "        [-0.0868],\n",
      "        [-0.0795]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.Tensor(X_test.values)\n",
    "pred_y_test = CNET.predict(X_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "052180b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0555],\n",
      "        [0.0562],\n",
      "        [0.0568],\n",
      "        [0.0699],\n",
      "        [0.0684],\n",
      "        [0.0575],\n",
      "        [0.0563],\n",
      "        [0.0556],\n",
      "        [0.0707],\n",
      "        [0.0575],\n",
      "        [0.0557],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0560],\n",
      "        [0.0564],\n",
      "        [0.0560],\n",
      "        [0.0616],\n",
      "        [0.0563],\n",
      "        [0.0609],\n",
      "        [0.0655],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0558],\n",
      "        [0.0574],\n",
      "        [0.0590],\n",
      "        [0.0561],\n",
      "        [0.0558],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0602],\n",
      "        [0.0586],\n",
      "        [0.0565],\n",
      "        [0.0714],\n",
      "        [0.0250],\n",
      "        [0.0621],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0622],\n",
      "        [0.0564],\n",
      "        [0.0558],\n",
      "        [0.0661],\n",
      "        [0.0560],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0562],\n",
      "        [0.0616],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0611],\n",
      "        [0.0588],\n",
      "        [0.0597],\n",
      "        [0.0587],\n",
      "        [0.0557],\n",
      "        [0.0668],\n",
      "        [0.0705],\n",
      "        [0.0558],\n",
      "        [0.0573],\n",
      "        [0.0561],\n",
      "        [0.0745],\n",
      "        [0.0768],\n",
      "        [0.0601],\n",
      "        [0.0560],\n",
      "        [0.0598],\n",
      "        [0.0557],\n",
      "        [0.0720],\n",
      "        [0.0559],\n",
      "        [0.0626],\n",
      "        [0.0771],\n",
      "        [0.0566],\n",
      "        [0.0556],\n",
      "        [0.0563],\n",
      "        [0.0673],\n",
      "        [0.0694],\n",
      "        [0.0559],\n",
      "        [0.0552],\n",
      "        [0.0611],\n",
      "        [0.0566],\n",
      "        [0.0555],\n",
      "        [0.0597],\n",
      "        [0.0661],\n",
      "        [0.0701],\n",
      "        [0.0557],\n",
      "        [0.0557],\n",
      "        [0.0820],\n",
      "        [0.0683],\n",
      "        [0.0570],\n",
      "        [0.0873],\n",
      "        [0.0562],\n",
      "        [0.0565],\n",
      "        [0.0558],\n",
      "        [0.0551],\n",
      "        [0.0692],\n",
      "        [0.0561],\n",
      "        [0.0598],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0554],\n",
      "        [0.0565],\n",
      "        [0.0615],\n",
      "        [0.0562],\n",
      "        [0.0560],\n",
      "        [0.0584],\n",
      "        [0.0697],\n",
      "        [0.0615],\n",
      "        [0.0632],\n",
      "        [0.0605],\n",
      "        [0.0600],\n",
      "        [0.0556],\n",
      "        [0.0785],\n",
      "        [0.0560],\n",
      "        [0.0795],\n",
      "        [0.0585],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0685],\n",
      "        [0.0554],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.0555],\n",
      "        [0.0919],\n",
      "        [0.0559],\n",
      "        [0.0712],\n",
      "        [0.0555],\n",
      "        [0.0554],\n",
      "        [0.0641],\n",
      "        [0.0627],\n",
      "        [0.0558],\n",
      "        [0.0556],\n",
      "        [0.0558],\n",
      "        [0.0559],\n",
      "        [0.0563],\n",
      "        [0.1138],\n",
      "        [0.0587],\n",
      "        [0.0579],\n",
      "        [0.0557],\n",
      "        [0.0706],\n",
      "        [0.0569],\n",
      "        [0.0557],\n",
      "        [0.0559],\n",
      "        [0.0558],\n",
      "        [0.0555],\n",
      "        [0.0559],\n",
      "        [0.0697],\n",
      "        [0.0564],\n",
      "        [0.0566],\n",
      "        [0.0558],\n",
      "        [0.0663],\n",
      "        [0.0555],\n",
      "        [0.0569],\n",
      "        [0.0553],\n",
      "        [0.0565],\n",
      "        [0.0815],\n",
      "        [0.0556],\n",
      "        [0.0766],\n",
      "        [0.0600],\n",
      "        [0.0701],\n",
      "        [0.0712],\n",
      "        [0.0561],\n",
      "        [0.0565],\n",
      "        [0.0686],\n",
      "        [0.0681],\n",
      "        [0.0556],\n",
      "        [0.0715],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.1097],\n",
      "        [0.0607],\n",
      "        [0.0586],\n",
      "        [0.0564],\n",
      "        [0.0555],\n",
      "        [0.0561],\n",
      "        [0.0654],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0608],\n",
      "        [0.0563],\n",
      "        [0.0565],\n",
      "        [0.0563],\n",
      "        [0.0860],\n",
      "        [0.0595],\n",
      "        [0.1062],\n",
      "        [0.0557],\n",
      "        [0.0561],\n",
      "        [0.0786],\n",
      "        [0.0562],\n",
      "        [0.0561],\n",
      "        [0.0796],\n",
      "        [0.0656],\n",
      "        [0.0568],\n",
      "        [0.0564],\n",
      "        [0.0557],\n",
      "        [0.0587],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0561]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X1_test = torch.Tensor(X1_test.values)\n",
    "pred_y_test = RNET.predict(X1_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856f713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f73cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316d6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23089968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af90136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a25ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa8d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963271e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eb133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac47b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
