{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1987f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE_regression(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea16fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuralNet (Regression)\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "                \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuralNet (Classification)\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b25f3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNet(X_train, y_train, X_test,y_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "    '''\n",
    "    \n",
    "        @Input \n",
    "            X_train : type : array\n",
    "            y_train : type : array\n",
    "            X_test : type : array\n",
    "            hiddenlayer : type : int\n",
    "            node : type : int\n",
    "            Ouputnode : type : int\n",
    "            epochs : type : int\n",
    "            \n",
    "        @Output\n",
    "            pred_y_test : type : array\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    \n",
    "    # 학습을 위한 데이터 전처리 \n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    #신경망 생성하기\n",
    "    model = ClassificationNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "    \n",
    "    \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"CNet.pt\")\n",
    "    \n",
    "    #테스트 데이터로 예측 결과 반환\n",
    "    pred_y_test = model.predict(X_test)\n",
    "    \n",
    "    #파이토치 텐서를 넘파이 어레이로 전환\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "      # calculate AUC of model\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_y_test)\n",
    "    auc = roc_auc_score(y_test, pred_y_test)\n",
    "      \n",
    "    return  {\"auc_score\": auc, \"fpr\":fpr, \"tpr\":tpr}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c71270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNet(X_train, y_train, X_test, y_test , hiddenlayer, node, Ouputnode, epochs):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        @Input \n",
    "            X_train : type : array\n",
    "            y_train : type : array\n",
    "            X_test : type : array\n",
    "            hiddenlayer : type : int\n",
    "            node : type : int\n",
    "            Ouputnode : type : int\n",
    "            epochs : type : int\n",
    "            \n",
    "        @Output\n",
    "            pred_y_test : type : array\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    \n",
    "    # 학습을 위한 데이터 전처리 \n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 신경망 생성하기\n",
    "    model = RegressionNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "            \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"RNet.pt\")\n",
    "    \n",
    "    #테스트 데이터로 예측 결과 반환\n",
    "    pred_y_test = model.predict(X_test)\n",
    "    \n",
    "    #파이토치 텐서를 넘파이 어레이로 전환\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "    MSE = mean_squared_error(y_test, pred_y_test)  # MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\n",
    "    \n",
    "    # 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAPE = MAPE_regression(y_test, pred_y_test)\n",
    "    R_squared = r2_score(y_test, pred_y_test)\n",
    "    return {'pred_y' : pred_y_test, 'RMSE' : RMSE, 'MAPE' : MAPE, \"R_squared\" : R_squared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08163130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ab_te.csv\")\n",
    "df2 = pd.read_csv(\"RMS_bearing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53543fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.iloc[:,[0, 1, 2, 3]]\n",
    "y = df1.iloc[:,[4]]\n",
    "x1 = df2.iloc[:,[0,1,2]]\n",
    "y1 = df2.iloc[:,[3]]\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=33)\n",
    "\n",
    "X1_train,X1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8308379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "0epoch // loss =-0.0\n",
      "torch.FloatTensor\n",
      "tensor([[-0.2137],\n",
      "        [-0.1985],\n",
      "        [-0.2117],\n",
      "        [-0.2139],\n",
      "        [-0.1754],\n",
      "        [-0.2121],\n",
      "        [-0.2096],\n",
      "        [-0.2032],\n",
      "        [-0.2048],\n",
      "        [-0.2004],\n",
      "        [-0.1987],\n",
      "        [-0.2110],\n",
      "        [-0.2126],\n",
      "        [-0.2042],\n",
      "        [-0.2046],\n",
      "        [-0.2086],\n",
      "        [-0.2124],\n",
      "        [-0.2146],\n",
      "        [-0.2077],\n",
      "        [-0.2126],\n",
      "        [-0.1896],\n",
      "        [-0.2095],\n",
      "        [-0.2225],\n",
      "        [-0.1378],\n",
      "        [-0.2087],\n",
      "        [-0.2100],\n",
      "        [-0.1988],\n",
      "        [-0.2013],\n",
      "        [-0.1989],\n",
      "        [-0.2099],\n",
      "        [-0.2147],\n",
      "        [-0.2155],\n",
      "        [-0.2133],\n",
      "        [-0.2132],\n",
      "        [-0.2087],\n",
      "        [-0.2079],\n",
      "        [-0.2150],\n",
      "        [-0.2000],\n",
      "        [-0.2051],\n",
      "        [-0.2005],\n",
      "        [-0.2077],\n",
      "        [-0.2128],\n",
      "        [-0.1970],\n",
      "        [-0.2074],\n",
      "        [-0.1920],\n",
      "        [-0.2096],\n",
      "        [-0.2089],\n",
      "        [-0.2054],\n",
      "        [-0.2204],\n",
      "        [-0.2067],\n",
      "        [-0.2129],\n",
      "        [-0.2082],\n",
      "        [-0.2490],\n",
      "        [-0.2099],\n",
      "        [-0.2079],\n",
      "        [-0.1818],\n",
      "        [-0.2203],\n",
      "        [-0.2014],\n",
      "        [-0.2128],\n",
      "        [-0.2102],\n",
      "        [-0.1997],\n",
      "        [-0.1961],\n",
      "        [-0.1473],\n",
      "        [-0.2091],\n",
      "        [-0.2138],\n",
      "        [-0.2242],\n",
      "        [-0.2137],\n",
      "        [-0.2151],\n",
      "        [-0.2022],\n",
      "        [-0.2041],\n",
      "        [-0.2015],\n",
      "        [-0.2172],\n",
      "        [-0.2088],\n",
      "        [-0.2111],\n",
      "        [-0.2124],\n",
      "        [-0.2114],\n",
      "        [-0.2062],\n",
      "        [-0.2038],\n",
      "        [-0.2086],\n",
      "        [-0.2110],\n",
      "        [-0.2027],\n",
      "        [-0.2105],\n",
      "        [-0.2073],\n",
      "        [-0.2094],\n",
      "        [-0.1996],\n",
      "        [-0.2104],\n",
      "        [-0.2053],\n",
      "        [-0.2158],\n",
      "        [-0.2147],\n",
      "        [-0.1850],\n",
      "        [-0.2013],\n",
      "        [-0.2131],\n",
      "        [-0.1989],\n",
      "        [-0.1889],\n",
      "        [-0.2098],\n",
      "        [-0.2109],\n",
      "        [-0.2152],\n",
      "        [-0.1830],\n",
      "        [-0.2138],\n",
      "        [-0.2089],\n",
      "        [-0.2098],\n",
      "        [-0.2148],\n",
      "        [-0.2106],\n",
      "        [-0.2000],\n",
      "        [-0.2135],\n",
      "        [-0.2033],\n",
      "        [-0.2048],\n",
      "        [-0.2045],\n",
      "        [-0.2094],\n",
      "        [-0.2133],\n",
      "        [-0.2152],\n",
      "        [-0.2149],\n",
      "        [-0.2077],\n",
      "        [-0.2164],\n",
      "        [-0.2133],\n",
      "        [-0.2042],\n",
      "        [-0.1992],\n",
      "        [-0.2018],\n",
      "        [-0.2045],\n",
      "        [-0.2038],\n",
      "        [-0.2108],\n",
      "        [-0.2103],\n",
      "        [-0.1982],\n",
      "        [-0.1994],\n",
      "        [-0.2034],\n",
      "        [-0.2027],\n",
      "        [-0.2236],\n",
      "        [-0.1380],\n",
      "        [-0.2046],\n",
      "        [-0.2177],\n",
      "        [-0.1983],\n",
      "        [-0.2018],\n",
      "        [-0.2028],\n",
      "        [-0.2071],\n",
      "        [-0.2142],\n",
      "        [-0.2114],\n",
      "        [-0.2217],\n",
      "        [-0.2103],\n",
      "        [-0.1965],\n",
      "        [-0.2128],\n",
      "        [-0.2034],\n",
      "        [-0.2129],\n",
      "        [-0.2081],\n",
      "        [-0.2098],\n",
      "        [-0.2082],\n",
      "        [-0.1952],\n",
      "        [-0.1618],\n",
      "        [-0.2158],\n",
      "        [-0.2070],\n",
      "        [-0.2535],\n",
      "        [-0.2076],\n",
      "        [-0.2044],\n",
      "        [-0.1716],\n",
      "        [-0.2089],\n",
      "        [-0.2177],\n",
      "        [-0.2015],\n",
      "        [-0.2057],\n",
      "        [-0.2116],\n",
      "        [-0.2086],\n",
      "        [-0.1775],\n",
      "        [-0.2223],\n",
      "        [-0.2430],\n",
      "        [-0.2042],\n",
      "        [-0.2063],\n",
      "        [-0.2142],\n",
      "        [-0.2704],\n",
      "        [-0.2072],\n",
      "        [-0.2043],\n",
      "        [-0.2112],\n",
      "        [-0.2002],\n",
      "        [-0.2132],\n",
      "        [-0.2411],\n",
      "        [-0.2003],\n",
      "        [-0.2095],\n",
      "        [-0.2056],\n",
      "        [-0.1940],\n",
      "        [-0.2109],\n",
      "        [-0.2055],\n",
      "        [-0.1998],\n",
      "        [-0.1814],\n",
      "        [-0.2126],\n",
      "        [-0.2120],\n",
      "        [-0.2140],\n",
      "        [-0.2135],\n",
      "        [-0.1805],\n",
      "        [-0.2098],\n",
      "        [-0.2029],\n",
      "        [-0.2039],\n",
      "        [-0.2154],\n",
      "        [-0.2355],\n",
      "        [-0.2088],\n",
      "        [-0.2026],\n",
      "        [-0.2104],\n",
      "        [-0.2183],\n",
      "        [-0.2075],\n",
      "        [-0.2343],\n",
      "        [-0.2100],\n",
      "        [-0.2236],\n",
      "        [-0.2164],\n",
      "        [-0.2076],\n",
      "        [-0.2064],\n",
      "        [-0.2218],\n",
      "        [-0.2264],\n",
      "        [-0.2110],\n",
      "        [-0.2221],\n",
      "        [-0.2036],\n",
      "        [-0.1575],\n",
      "        [-0.1673],\n",
      "        [-0.2049],\n",
      "        [-0.2036],\n",
      "        [-0.1822],\n",
      "        [-0.2033],\n",
      "        [-0.2134],\n",
      "        [-0.2039],\n",
      "        [-0.1943],\n",
      "        [-0.2063],\n",
      "        [-0.2123],\n",
      "        [-0.2131],\n",
      "        [-0.2069],\n",
      "        [-0.2094],\n",
      "        [-0.2015],\n",
      "        [-0.2140],\n",
      "        [-0.1811],\n",
      "        [-0.1944],\n",
      "        [-0.2056],\n",
      "        [-0.2199],\n",
      "        [-0.2245],\n",
      "        [-0.2015],\n",
      "        [-0.2142],\n",
      "        [-0.2085],\n",
      "        [-0.2049],\n",
      "        [-0.2149],\n",
      "        [-0.2078],\n",
      "        [-0.1663],\n",
      "        [-0.2019],\n",
      "        [-0.2140],\n",
      "        [-0.2052],\n",
      "        [-0.2112],\n",
      "        [-0.2016],\n",
      "        [-0.2015]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m auc , fpr, tpr\u001b[38;5;241m=\u001b[39m \u001b[43mCNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mCNet\u001b[0;34m(X_train, y_train, X_test, y_test, hiddenlayer, node, Ouputnode, epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(pred_y_test)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#파이토치 텐서를 넘파이 어레이로 전환\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m pred_y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpred_y_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m   \u001b[38;5;66;03m# calculate AUC of model\u001b[39;00m\n\u001b[1;32m     46\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m roc_curve(y_test, pred_y_test)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "auc , fpr, tpr= CNet(X_train, y_train, X_test,y_test, 2, 5, 1, 10)\n",
    "#CNet(X_train, y_train, X_test,y_test, hiddenlayer, node, Ouputnode, epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18d5423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch // loss =1.0361895874666516e-05\n"
     ]
    }
   ],
   "source": [
    "pred_y1_test = RNet(X1_train, y1_train, X1_test, y1_test, 2, 5, 1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667426f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_y': array([[0.05252028],\n",
      "       [0.05328456],\n",
      "       [0.05420646],\n",
      "       [0.06804861],\n",
      "       [0.06640811],\n",
      "       [0.05514751],\n",
      "       [0.05348556],\n",
      "       [0.05286469],\n",
      "       [0.0684787 ],\n",
      "       [0.05510148],\n",
      "       [0.05313033],\n",
      "       [0.05324189],\n",
      "       [0.05278341],\n",
      "       [0.05376489],\n",
      "       [0.05340834],\n",
      "       [0.05405645],\n",
      "       [0.05359069],\n",
      "       [0.05904232],\n",
      "       [0.05377343],\n",
      "       [0.05809842],\n",
      "       [0.06306078],\n",
      "       [0.05320136],\n",
      "       [0.05350685],\n",
      "       [0.05317663],\n",
      "       [0.05497015],\n",
      "       [0.05665414],\n",
      "       [0.05341689],\n",
      "       [0.05326344],\n",
      "       [0.0532288 ],\n",
      "       [0.05416496],\n",
      "       [0.05806811],\n",
      "       [0.05620381],\n",
      "       [0.05371985],\n",
      "       [0.06892097],\n",
      "       [0.0283269 ],\n",
      "       [0.0591922 ],\n",
      "       [0.05317321],\n",
      "       [0.05412509],\n",
      "       [0.0594434 ],\n",
      "       [0.05387323],\n",
      "       [0.05331795],\n",
      "       [0.06411456],\n",
      "       [0.05317381],\n",
      "       [0.05317973],\n",
      "       [0.05322108],\n",
      "       [0.05356781],\n",
      "       [0.05890553],\n",
      "       [0.05352212],\n",
      "       [0.05383122],\n",
      "       [0.05815153],\n",
      "       [0.05617969],\n",
      "       [0.05742052],\n",
      "       [0.0562347 ],\n",
      "       [0.05306891],\n",
      "       [0.06469555],\n",
      "       [0.06860508],\n",
      "       [0.05324601],\n",
      "       [0.05509192],\n",
      "       [0.05330652],\n",
      "       [0.07076305],\n",
      "       [0.07284771],\n",
      "       [0.05790387],\n",
      "       [0.05339675],\n",
      "       [0.05749086],\n",
      "       [0.05292568],\n",
      "       [0.06968126],\n",
      "       [0.05330089],\n",
      "       [0.06031331],\n",
      "       [0.07304038],\n",
      "       [0.05368528],\n",
      "       [0.05311941],\n",
      "       [0.05376521],\n",
      "       [0.06529589],\n",
      "       [0.06682412],\n",
      "       [0.05321099],\n",
      "       [0.05269957],\n",
      "       [0.05840831],\n",
      "       [0.05392964],\n",
      "       [0.05300157],\n",
      "       [0.0574096 ],\n",
      "       [0.06244522],\n",
      "       [0.06806602],\n",
      "       [0.05305313],\n",
      "       [0.05309026],\n",
      "       [0.0774367 ],\n",
      "       [0.06588709],\n",
      "       [0.05439489],\n",
      "       [0.08284727],\n",
      "       [0.05344947],\n",
      "       [0.05380698],\n",
      "       [0.05302635],\n",
      "       [0.05280574],\n",
      "       [0.06615193],\n",
      "       [0.05327235],\n",
      "       [0.05742308],\n",
      "       [0.0534212 ],\n",
      "       [0.05416323],\n",
      "       [0.05291681],\n",
      "       [0.05416366],\n",
      "       [0.05885084],\n",
      "       [0.05335815],\n",
      "       [0.05318329],\n",
      "       [0.05617881],\n",
      "       [0.06694262],\n",
      "       [0.0588769 ],\n",
      "       [0.06067804],\n",
      "       [0.05777951],\n",
      "       [0.05783439],\n",
      "       [0.05299243],\n",
      "       [0.07434173],\n",
      "       [0.0532141 ],\n",
      "       [0.07601304],\n",
      "       [0.0560071 ],\n",
      "       [0.05282305],\n",
      "       [0.05322354],\n",
      "       [0.06601422],\n",
      "       [0.052931  ],\n",
      "       [0.05312113],\n",
      "       [0.05337024],\n",
      "       [0.05286595],\n",
      "       [0.08473851],\n",
      "       [0.05312021],\n",
      "       [0.06932059],\n",
      "       [0.05302048],\n",
      "       [0.05274884],\n",
      "       [0.06139109],\n",
      "       [0.06025623],\n",
      "       [0.05318223],\n",
      "       [0.05298746],\n",
      "       [0.05281381],\n",
      "       [0.05319603],\n",
      "       [0.0534939 ],\n",
      "       [0.10583249],\n",
      "       [0.05621499],\n",
      "       [0.05547069],\n",
      "       [0.05297635],\n",
      "       [0.06771536],\n",
      "       [0.05458838],\n",
      "       [0.05307108],\n",
      "       [0.05339445],\n",
      "       [0.05319051],\n",
      "       [0.05293156],\n",
      "       [0.05307193],\n",
      "       [0.06759003],\n",
      "       [0.05371702],\n",
      "       [0.05404188],\n",
      "       [0.05314519],\n",
      "       [0.0641052 ],\n",
      "       [0.0528643 ],\n",
      "       [0.05445559],\n",
      "       [0.05287929],\n",
      "       [0.05365503],\n",
      "       [0.07774897],\n",
      "       [0.05309451],\n",
      "       [0.07302687],\n",
      "       [0.05777843],\n",
      "       [0.06699111],\n",
      "       [0.06943552],\n",
      "       [0.05352296],\n",
      "       [0.05384481],\n",
      "       [0.06643252],\n",
      "       [0.06557828],\n",
      "       [0.05284761],\n",
      "       [0.06941274],\n",
      "       [0.05340607],\n",
      "       [0.05316022],\n",
      "       [0.10529606],\n",
      "       [0.05772372],\n",
      "       [0.0559251 ],\n",
      "       [0.05367625],\n",
      "       [0.05294968],\n",
      "       [0.05328318],\n",
      "       [0.06304525],\n",
      "       [0.05275907],\n",
      "       [0.05343518],\n",
      "       [0.05363376],\n",
      "       [0.05776331],\n",
      "       [0.05355692],\n",
      "       [0.0539398 ],\n",
      "       [0.05409227],\n",
      "       [0.08233188],\n",
      "       [0.05729465],\n",
      "       [0.09833752],\n",
      "       [0.0530806 ],\n",
      "       [0.05375871],\n",
      "       [0.07486242],\n",
      "       [0.05324839],\n",
      "       [0.05323404],\n",
      "       [0.0755531 ],\n",
      "       [0.06301378],\n",
      "       [0.05415924],\n",
      "       [0.05358139],\n",
      "       [0.05292544],\n",
      "       [0.05626369],\n",
      "       [0.05347255],\n",
      "       [0.05371393],\n",
      "       [0.05376182]], dtype=float32), 'RMSE': 0.00413511473031198, 'MAPE': ch4    10.082154\n",
      "dtype: float64, 'R_squared': 0.8645047158991692}\n"
     ]
    }
   ],
   "source": [
    "print(pred_y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8551fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=3, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNET = torch.load(\"RNet.pt\")\n",
    "RNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c155a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNET = torch.load(\"CNet.pt\")\n",
    "CNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0326758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4473],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4480],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4459],\n",
      "        [-0.4484],\n",
      "        [-0.4477],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4477],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4473],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4478],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4477],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4440],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4390],\n",
      "        [-0.4479],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4477],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4451],\n",
      "        [-0.4482],\n",
      "        [-0.4480],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4480],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4478],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4440],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4413],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4482],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4486],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4483],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4481],\n",
      "        [-0.4473],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4398],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4329],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4473],\n",
      "        [-0.4473],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4479],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4483],\n",
      "        [-0.4477],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4483],\n",
      "        [-0.4482],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4480],\n",
      "        [-0.4346],\n",
      "        [-0.4479],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4473],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4481],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4473],\n",
      "        [-0.4484],\n",
      "        [-0.4479],\n",
      "        [-0.4481],\n",
      "        [-0.4358],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4482],\n",
      "        [-0.4484],\n",
      "        [-0.4305],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4477],\n",
      "        [-0.4384],\n",
      "        [-0.4453],\n",
      "        [-0.4484],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4288],\n",
      "        [-0.4483],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484],\n",
      "        [-0.4484]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.Tensor(X_test.values)\n",
    "pred_y_test = CNET.predict(X_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052180b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0525],\n",
      "        [0.0533],\n",
      "        [0.0542],\n",
      "        [0.0680],\n",
      "        [0.0664],\n",
      "        [0.0551],\n",
      "        [0.0535],\n",
      "        [0.0529],\n",
      "        [0.0685],\n",
      "        [0.0551],\n",
      "        [0.0531],\n",
      "        [0.0532],\n",
      "        [0.0528],\n",
      "        [0.0538],\n",
      "        [0.0534],\n",
      "        [0.0541],\n",
      "        [0.0536],\n",
      "        [0.0590],\n",
      "        [0.0538],\n",
      "        [0.0581],\n",
      "        [0.0631],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.0532],\n",
      "        [0.0550],\n",
      "        [0.0567],\n",
      "        [0.0534],\n",
      "        [0.0533],\n",
      "        [0.0532],\n",
      "        [0.0542],\n",
      "        [0.0581],\n",
      "        [0.0562],\n",
      "        [0.0537],\n",
      "        [0.0689],\n",
      "        [0.0283],\n",
      "        [0.0592],\n",
      "        [0.0532],\n",
      "        [0.0541],\n",
      "        [0.0594],\n",
      "        [0.0539],\n",
      "        [0.0533],\n",
      "        [0.0641],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0536],\n",
      "        [0.0589],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0582],\n",
      "        [0.0562],\n",
      "        [0.0574],\n",
      "        [0.0562],\n",
      "        [0.0531],\n",
      "        [0.0647],\n",
      "        [0.0686],\n",
      "        [0.0532],\n",
      "        [0.0551],\n",
      "        [0.0533],\n",
      "        [0.0708],\n",
      "        [0.0728],\n",
      "        [0.0579],\n",
      "        [0.0534],\n",
      "        [0.0575],\n",
      "        [0.0529],\n",
      "        [0.0697],\n",
      "        [0.0533],\n",
      "        [0.0603],\n",
      "        [0.0730],\n",
      "        [0.0537],\n",
      "        [0.0531],\n",
      "        [0.0538],\n",
      "        [0.0653],\n",
      "        [0.0668],\n",
      "        [0.0532],\n",
      "        [0.0527],\n",
      "        [0.0584],\n",
      "        [0.0539],\n",
      "        [0.0530],\n",
      "        [0.0574],\n",
      "        [0.0624],\n",
      "        [0.0681],\n",
      "        [0.0531],\n",
      "        [0.0531],\n",
      "        [0.0774],\n",
      "        [0.0659],\n",
      "        [0.0544],\n",
      "        [0.0828],\n",
      "        [0.0534],\n",
      "        [0.0538],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0662],\n",
      "        [0.0533],\n",
      "        [0.0574],\n",
      "        [0.0534],\n",
      "        [0.0542],\n",
      "        [0.0529],\n",
      "        [0.0542],\n",
      "        [0.0589],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0562],\n",
      "        [0.0669],\n",
      "        [0.0589],\n",
      "        [0.0607],\n",
      "        [0.0578],\n",
      "        [0.0578],\n",
      "        [0.0530],\n",
      "        [0.0743],\n",
      "        [0.0532],\n",
      "        [0.0760],\n",
      "        [0.0560],\n",
      "        [0.0528],\n",
      "        [0.0532],\n",
      "        [0.0660],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0529],\n",
      "        [0.0847],\n",
      "        [0.0531],\n",
      "        [0.0693],\n",
      "        [0.0530],\n",
      "        [0.0527],\n",
      "        [0.0614],\n",
      "        [0.0603],\n",
      "        [0.0532],\n",
      "        [0.0530],\n",
      "        [0.0528],\n",
      "        [0.0532],\n",
      "        [0.0535],\n",
      "        [0.1058],\n",
      "        [0.0562],\n",
      "        [0.0555],\n",
      "        [0.0530],\n",
      "        [0.0677],\n",
      "        [0.0546],\n",
      "        [0.0531],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.0529],\n",
      "        [0.0531],\n",
      "        [0.0676],\n",
      "        [0.0537],\n",
      "        [0.0540],\n",
      "        [0.0531],\n",
      "        [0.0641],\n",
      "        [0.0529],\n",
      "        [0.0545],\n",
      "        [0.0529],\n",
      "        [0.0537],\n",
      "        [0.0777],\n",
      "        [0.0531],\n",
      "        [0.0730],\n",
      "        [0.0578],\n",
      "        [0.0670],\n",
      "        [0.0694],\n",
      "        [0.0535],\n",
      "        [0.0538],\n",
      "        [0.0664],\n",
      "        [0.0656],\n",
      "        [0.0528],\n",
      "        [0.0694],\n",
      "        [0.0534],\n",
      "        [0.0532],\n",
      "        [0.1053],\n",
      "        [0.0577],\n",
      "        [0.0559],\n",
      "        [0.0537],\n",
      "        [0.0529],\n",
      "        [0.0533],\n",
      "        [0.0630],\n",
      "        [0.0528],\n",
      "        [0.0534],\n",
      "        [0.0536],\n",
      "        [0.0578],\n",
      "        [0.0536],\n",
      "        [0.0539],\n",
      "        [0.0541],\n",
      "        [0.0823],\n",
      "        [0.0573],\n",
      "        [0.0983],\n",
      "        [0.0531],\n",
      "        [0.0538],\n",
      "        [0.0749],\n",
      "        [0.0532],\n",
      "        [0.0532],\n",
      "        [0.0756],\n",
      "        [0.0630],\n",
      "        [0.0542],\n",
      "        [0.0536],\n",
      "        [0.0529],\n",
      "        [0.0563],\n",
      "        [0.0535],\n",
      "        [0.0537],\n",
      "        [0.0538]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X1_test = torch.Tensor(X1_test.values)\n",
    "pred_y_test = RNET.predict(X1_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a856f713",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got builtin_function_or_method)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X1_test \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got builtin_function_or_method)"
     ]
    }
   ],
   "source": [
    "X1_test = torch.Tensor(X1_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f73cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316d6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23089968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af90136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a25ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa8d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963271e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eb133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac47b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
