{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55fc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1987f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE_regression(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea16fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "                \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d62eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        print(self.layer1)\n",
    "        \n",
    "    def predict(self, X_train):\n",
    "        pred_x = self.layer1(X_train)\n",
    "        \n",
    "        return pred_x\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b25f3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNet(X_train, y_train, X_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    #신경망 생성하기\n",
    "    model = ClassificationNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "    \n",
    "    \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"CNet.pt\")\n",
    "    \n",
    "    pred_y_test = model.predict(X_test)\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "      # calculate AUC of model\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_y_test)\n",
    "    auc = roc_auc_score(y_test, pred_y_test)\n",
    "      \n",
    "    return  ({\"auc_score\": auc, \"fpr\":fpr, \"tpr\":tpr})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c71270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNet(X_train, y_train, X_test, y_test , hiddenlayer, node, Ouputnode, epochs):\n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 신경망 생성하기\n",
    "    model = RegressionNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "            \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"RNet.pt\")\n",
    "    \n",
    "    pred_y_test = model.predict(X_test)\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "    MSE = mean_squared_error(y_test, pred_y_test)  # MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\n",
    "    \n",
    "    # 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAPE = MAPE_regression(y_test, pred_y_test)\n",
    "    R_squared = r2_score(y_test, pred_y_test)\n",
    "    return {'pred_y' : pred_y_test, 'RMSE' : RMSE, 'MAPE' : MAPE, \"R_squared\" : R_squared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08163130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ab_te.csv\")\n",
    "df2 = pd.read_csv(\"RMS_bearing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53543fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.iloc[:,[0, 1, 2, 3]]\n",
    "y = df1.iloc[:,[4]]\n",
    "x1 = df2.iloc[:,[0,1,2]]\n",
    "y1 = df2.iloc[:,[3]]\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=33)\n",
    "\n",
    "X1_train,X1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8308379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "0epoch // loss =-0.0\n"
     ]
    }
   ],
   "source": [
    "pred_y_test = CNet(X_train, y_train, X_test, 2, 5, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d7dde1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc_score': 0.4722145040288969, 'fpr': array([0.        , 0.00819672, 0.01639344, 0.01639344, 0.02459016,\n",
      "       0.02459016, 0.04918033, 0.04918033, 0.06557377, 0.06557377,\n",
      "       0.07377049, 0.07377049, 0.09016393, 0.09016393, 0.09836066,\n",
      "       0.09836066, 0.10655738, 0.10655738, 0.12295082, 0.12295082,\n",
      "       0.13114754, 0.13114754, 0.1557377 , 0.1557377 , 0.17213115,\n",
      "       0.17213115, 0.18032787, 0.18032787, 0.21311475, 0.21311475,\n",
      "       0.2295082 , 0.2295082 , 0.25409836, 0.25409836, 0.27868852,\n",
      "       0.27868852, 0.29508197, 0.29508197, 0.30327869, 0.30327869,\n",
      "       0.31147541, 0.31147541, 0.31967213, 0.31967213, 0.33606557,\n",
      "       0.33606557, 0.36885246, 0.36885246, 0.43442623, 0.43442623,\n",
      "       0.44262295, 0.44262295, 0.5       , 0.5       , 0.50819672,\n",
      "       0.50819672, 0.51639344, 0.51639344, 0.53278689, 0.53278689,\n",
      "       0.54918033, 0.54918033, 0.55737705, 0.55737705, 0.56557377,\n",
      "       0.56557377, 0.58196721, 0.58196721, 0.59016393, 0.59016393,\n",
      "       0.59836066, 0.59836066, 0.6147541 , 0.6147541 , 0.62295082,\n",
      "       0.62295082, 0.63114754, 0.63114754, 0.63934426, 0.63934426,\n",
      "       0.6557377 , 0.6557377 , 0.68032787, 0.68032787, 0.68852459,\n",
      "       0.68852459, 0.73770492, 0.73770492, 0.74590164, 0.74590164,\n",
      "       0.75409836, 0.75409836, 0.77868852, 0.77868852, 0.79508197,\n",
      "       0.79508197, 0.81147541, 0.81147541, 0.82786885, 0.82786885,\n",
      "       0.83606557, 0.83606557, 0.91803279, 0.91803279, 0.92622951,\n",
      "       0.92622951, 0.93442623, 0.93442623, 0.94262295, 0.94262295,\n",
      "       0.95081967, 0.95081967, 0.95901639, 0.95901639, 0.96721311,\n",
      "       0.96721311, 0.97540984, 0.97540984, 1.        , 1.        ]), 'tpr': array([0.        , 0.        , 0.        , 0.00847458, 0.00847458,\n",
      "       0.01694915, 0.01694915, 0.02542373, 0.02542373, 0.03389831,\n",
      "       0.03389831, 0.06779661, 0.06779661, 0.07627119, 0.07627119,\n",
      "       0.08474576, 0.08474576, 0.11016949, 0.11016949, 0.11864407,\n",
      "       0.11864407, 0.12711864, 0.12711864, 0.16101695, 0.16101695,\n",
      "       0.16949153, 0.16949153, 0.1779661 , 0.1779661 , 0.19491525,\n",
      "       0.19491525, 0.22033898, 0.22033898, 0.22881356, 0.22881356,\n",
      "       0.24576271, 0.24576271, 0.25423729, 0.25423729, 0.27966102,\n",
      "       0.27966102, 0.31355932, 0.31355932, 0.3220339 , 0.3220339 ,\n",
      "       0.33898305, 0.33898305, 0.34745763, 0.34745763, 0.36440678,\n",
      "       0.36440678, 0.37288136, 0.37288136, 0.38983051, 0.38983051,\n",
      "       0.39830508, 0.39830508, 0.40677966, 0.40677966, 0.44067797,\n",
      "       0.44067797, 0.44915254, 0.44915254, 0.47457627, 0.47457627,\n",
      "       0.50847458, 0.50847458, 0.51694915, 0.51694915, 0.52542373,\n",
      "       0.52542373, 0.54237288, 0.54237288, 0.55932203, 0.55932203,\n",
      "       0.57627119, 0.57627119, 0.58474576, 0.58474576, 0.62711864,\n",
      "       0.62711864, 0.63559322, 0.63559322, 0.68644068, 0.68644068,\n",
      "       0.70338983, 0.70338983, 0.76271186, 0.76271186, 0.77966102,\n",
      "       0.77966102, 0.78813559, 0.78813559, 0.80508475, 0.80508475,\n",
      "       0.83050847, 0.83050847, 0.83898305, 0.83898305, 0.86440678,\n",
      "       0.86440678, 0.88135593, 0.88135593, 0.88983051, 0.88983051,\n",
      "       0.91525424, 0.91525424, 0.92372881, 0.92372881, 0.94067797,\n",
      "       0.94067797, 0.94915254, 0.94915254, 0.96610169, 0.96610169,\n",
      "       0.98305085, 0.98305085, 0.99152542, 0.99152542, 1.        ])}\n"
     ]
    }
   ],
   "source": [
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18d5423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch // loss =8.144390335473872e-07\n"
     ]
    }
   ],
   "source": [
    "pred_y1_test = RNet(X1_train, y1_train, X1_test, y1_test, 2, 5, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e177169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pred_y': array([[0.05548748],\n",
      "       [0.05615787],\n",
      "       [0.05676073],\n",
      "       [0.06992605],\n",
      "       [0.06840664],\n",
      "       [0.05750173],\n",
      "       [0.05632113],\n",
      "       [0.05559295],\n",
      "       [0.07073781],\n",
      "       [0.0574763 ],\n",
      "       [0.05571398],\n",
      "       [0.05595627],\n",
      "       [0.05561461],\n",
      "       [0.05656603],\n",
      "       [0.05601814],\n",
      "       [0.05639952],\n",
      "       [0.05601397],\n",
      "       [0.06155373],\n",
      "       [0.05627134],\n",
      "       [0.06090382],\n",
      "       [0.06545442],\n",
      "       [0.05604333],\n",
      "       [0.05627555],\n",
      "       [0.05580342],\n",
      "       [0.05742972],\n",
      "       [0.05898267],\n",
      "       [0.05610825],\n",
      "       [0.05580124],\n",
      "       [0.05579217],\n",
      "       [0.05672863],\n",
      "       [0.06022389],\n",
      "       [0.05861458],\n",
      "       [0.056545  ],\n",
      "       [0.07139337],\n",
      "       [0.02501155],\n",
      "       [0.06207348],\n",
      "       [0.05560356],\n",
      "       [0.0565545 ],\n",
      "       [0.0621815 ],\n",
      "       [0.05636242],\n",
      "       [0.05577517],\n",
      "       [0.06610242],\n",
      "       [0.05602452],\n",
      "       [0.05596051],\n",
      "       [0.05558097],\n",
      "       [0.05620584],\n",
      "       [0.06158538],\n",
      "       [0.05613232],\n",
      "       [0.0564383 ],\n",
      "       [0.0610875 ],\n",
      "       [0.05875722],\n",
      "       [0.05971143],\n",
      "       [0.05872726],\n",
      "       [0.05568688],\n",
      "       [0.06676126],\n",
      "       [0.07046729],\n",
      "       [0.05584322],\n",
      "       [0.05727793],\n",
      "       [0.05606496],\n",
      "       [0.07448135],\n",
      "       [0.07681376],\n",
      "       [0.06012571],\n",
      "       [0.05597794],\n",
      "       [0.05977762],\n",
      "       [0.05569804],\n",
      "       [0.07200155],\n",
      "       [0.05586913],\n",
      "       [0.06258667],\n",
      "       [0.07712971],\n",
      "       [0.05660984],\n",
      "       [0.05563959],\n",
      "       [0.05631712],\n",
      "       [0.06731507],\n",
      "       [0.06938885],\n",
      "       [0.05587623],\n",
      "       [0.05519146],\n",
      "       [0.06109774],\n",
      "       [0.05663407],\n",
      "       [0.05547379],\n",
      "       [0.05967438],\n",
      "       [0.06605965],\n",
      "       [0.07008278],\n",
      "       [0.05572742],\n",
      "       [0.05572233],\n",
      "       [0.08199897],\n",
      "       [0.068277  ],\n",
      "       [0.05698866],\n",
      "       [0.08734447],\n",
      "       [0.05617663],\n",
      "       [0.05645683],\n",
      "       [0.05578837],\n",
      "       [0.05508968],\n",
      "       [0.06917751],\n",
      "       [0.05611992],\n",
      "       [0.05977668],\n",
      "       [0.05584012],\n",
      "       [0.05668205],\n",
      "       [0.05538061],\n",
      "       [0.05647664],\n",
      "       [0.0614951 ],\n",
      "       [0.05618474],\n",
      "       [0.05598322],\n",
      "       [0.05838561],\n",
      "       [0.06972191],\n",
      "       [0.06154419],\n",
      "       [0.06323147],\n",
      "       [0.06053063],\n",
      "       [0.06003165],\n",
      "       [0.05559731],\n",
      "       [0.07847218],\n",
      "       [0.05599239],\n",
      "       [0.07952917],\n",
      "       [0.05850282],\n",
      "       [0.05553308],\n",
      "       [0.05597138],\n",
      "       [0.0684709 ],\n",
      "       [0.05538017],\n",
      "       [0.05579601],\n",
      "       [0.05596787],\n",
      "       [0.05550388],\n",
      "       [0.09186089],\n",
      "       [0.0558871 ],\n",
      "       [0.07115057],\n",
      "       [0.05552724],\n",
      "       [0.05535674],\n",
      "       [0.0640991 ],\n",
      "       [0.06272699],\n",
      "       [0.05583629],\n",
      "       [0.05557133],\n",
      "       [0.05575079],\n",
      "       [0.05590898],\n",
      "       [0.0562669 ],\n",
      "       [0.11384702],\n",
      "       [0.0587443 ],\n",
      "       [0.05789733],\n",
      "       [0.0556848 ],\n",
      "       [0.07057431],\n",
      "       [0.05686563],\n",
      "       [0.05569407],\n",
      "       [0.05593666],\n",
      "       [0.05580623],\n",
      "       [0.05545694],\n",
      "       [0.05592871],\n",
      "       [0.06970407],\n",
      "       [0.05635488],\n",
      "       [0.05664772],\n",
      "       [0.05579177],\n",
      "       [0.06633958],\n",
      "       [0.0554969 ],\n",
      "       [0.05692811],\n",
      "       [0.05528969],\n",
      "       [0.05652738],\n",
      "       [0.08148989],\n",
      "       [0.05562255],\n",
      "       [0.07662761],\n",
      "       [0.06002079],\n",
      "       [0.07005908],\n",
      "       [0.07118896],\n",
      "       [0.05608279],\n",
      "       [0.05646282],\n",
      "       [0.06855023],\n",
      "       [0.06805032],\n",
      "       [0.05563018],\n",
      "       [0.07151228],\n",
      "       [0.0558075 ],\n",
      "       [0.05599624],\n",
      "       [0.10973328],\n",
      "       [0.06072387],\n",
      "       [0.05859281],\n",
      "       [0.05644181],\n",
      "       [0.05551639],\n",
      "       [0.05611315],\n",
      "       [0.06536329],\n",
      "       [0.05553964],\n",
      "       [0.05604309],\n",
      "       [0.05631712],\n",
      "       [0.06081215],\n",
      "       [0.05626547],\n",
      "       [0.05647776],\n",
      "       [0.05633555],\n",
      "       [0.08596063],\n",
      "       [0.05954108],\n",
      "       [0.10623181],\n",
      "       [0.0557012 ],\n",
      "       [0.05614403],\n",
      "       [0.07857253],\n",
      "       [0.05618297],\n",
      "       [0.05606222],\n",
      "       [0.07955393],\n",
      "       [0.06564981],\n",
      "       [0.05683863],\n",
      "       [0.05637361],\n",
      "       [0.05571212],\n",
      "       [0.05872016],\n",
      "       [0.05609211],\n",
      "       [0.05640325],\n",
      "       [0.05613822]], dtype=float32), 'RMSE': 0.0031936702637930265, 'MAPE': ch4    8.054113\n",
      "dtype: float64, 'R_squared': 0.9191780728589111}\n"
     ]
    }
   ],
   "source": [
    "print(pred_y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8551fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=3, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNET = torch.load(\"RNet.pt\")\n",
    "RNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c155a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNET = torch.load(\"CNet.pt\")\n",
    "CNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0326758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1013],\n",
      "        [-0.1066],\n",
      "        [-0.0729],\n",
      "        [-0.0628],\n",
      "        [-0.1021],\n",
      "        [-0.0902],\n",
      "        [-0.0893],\n",
      "        [-0.1044],\n",
      "        [-0.0548],\n",
      "        [-0.0786],\n",
      "        [-0.0996],\n",
      "        [-0.0758],\n",
      "        [-0.0576],\n",
      "        [-0.0892],\n",
      "        [-0.1011],\n",
      "        [-0.0693],\n",
      "        [-0.0749],\n",
      "        [-0.0762],\n",
      "        [-0.1049],\n",
      "        [-0.0645],\n",
      "        [-0.0915],\n",
      "        [-0.0816],\n",
      "        [-0.0663],\n",
      "        [-0.0922],\n",
      "        [-0.0608],\n",
      "        [-0.0853],\n",
      "        [-0.0695],\n",
      "        [-0.0698],\n",
      "        [-0.0787],\n",
      "        [-0.0999],\n",
      "        [-0.0945],\n",
      "        [-0.0626],\n",
      "        [-0.0829],\n",
      "        [-0.0840],\n",
      "        [-0.0659],\n",
      "        [-0.0735],\n",
      "        [-0.0968],\n",
      "        [-0.0650],\n",
      "        [-0.1009],\n",
      "        [-0.0986],\n",
      "        [-0.0753],\n",
      "        [-0.0589],\n",
      "        [-0.0964],\n",
      "        [-0.0725],\n",
      "        [-0.0634],\n",
      "        [-0.0694],\n",
      "        [-0.0702],\n",
      "        [-0.0725],\n",
      "        [-0.0662],\n",
      "        [-0.0904],\n",
      "        [-0.0758],\n",
      "        [-0.0726],\n",
      "        [-0.1124],\n",
      "        [-0.0676],\n",
      "        [-0.0878],\n",
      "        [-0.0773],\n",
      "        [-0.0642],\n",
      "        [-0.0843],\n",
      "        [-0.0617],\n",
      "        [-0.0685],\n",
      "        [-0.0986],\n",
      "        [-0.0802],\n",
      "        [-0.1079],\n",
      "        [-0.0703],\n",
      "        [-0.0776],\n",
      "        [-0.0652],\n",
      "        [-0.0616],\n",
      "        [-0.0980],\n",
      "        [-0.0778],\n",
      "        [-0.0929],\n",
      "        [-0.0711],\n",
      "        [-0.0713],\n",
      "        [-0.1026],\n",
      "        [-0.0590],\n",
      "        [-0.0690],\n",
      "        [-0.1003],\n",
      "        [-0.0706],\n",
      "        [-0.0704],\n",
      "        [-0.0930],\n",
      "        [-0.0877],\n",
      "        [-0.0705],\n",
      "        [-0.0714],\n",
      "        [-0.0756],\n",
      "        [-0.0749],\n",
      "        [-0.0810],\n",
      "        [-0.0813],\n",
      "        [-0.0705],\n",
      "        [-0.1062],\n",
      "        [-0.0765],\n",
      "        [-0.1071],\n",
      "        [-0.0916],\n",
      "        [-0.0690],\n",
      "        [-0.0798],\n",
      "        [-0.1033],\n",
      "        [-0.0862],\n",
      "        [-0.0868],\n",
      "        [-0.1039],\n",
      "        [-0.0903],\n",
      "        [-0.0674],\n",
      "        [-0.0764],\n",
      "        [-0.0893],\n",
      "        [-0.0764],\n",
      "        [-0.0923],\n",
      "        [-0.0871],\n",
      "        [-0.0650],\n",
      "        [-0.0721],\n",
      "        [-0.0851],\n",
      "        [-0.0789],\n",
      "        [-0.0826],\n",
      "        [-0.1046],\n",
      "        [-0.0688],\n",
      "        [-0.0899],\n",
      "        [-0.0756],\n",
      "        [-0.1042],\n",
      "        [-0.0643],\n",
      "        [-0.0772],\n",
      "        [-0.0817],\n",
      "        [-0.0841],\n",
      "        [-0.0751],\n",
      "        [-0.1023],\n",
      "        [-0.0613],\n",
      "        [-0.0828],\n",
      "        [-0.0912],\n",
      "        [-0.0842],\n",
      "        [-0.1049],\n",
      "        [-0.0815],\n",
      "        [-0.1044],\n",
      "        [-0.0946],\n",
      "        [-0.0712],\n",
      "        [-0.0607],\n",
      "        [-0.1024],\n",
      "        [-0.0911],\n",
      "        [-0.0871],\n",
      "        [-0.0829],\n",
      "        [-0.0638],\n",
      "        [-0.0749],\n",
      "        [-0.0714],\n",
      "        [-0.0762],\n",
      "        [-0.0971],\n",
      "        [-0.0959],\n",
      "        [-0.0844],\n",
      "        [-0.0919],\n",
      "        [-0.0655],\n",
      "        [-0.0751],\n",
      "        [-0.1046],\n",
      "        [-0.0859],\n",
      "        [-0.0919],\n",
      "        [-0.1055],\n",
      "        [-0.0728],\n",
      "        [-0.1096],\n",
      "        [-0.0673],\n",
      "        [-0.0841],\n",
      "        [-0.0836],\n",
      "        [-0.0790],\n",
      "        [-0.1064],\n",
      "        [-0.0889],\n",
      "        [-0.0787],\n",
      "        [-0.0655],\n",
      "        [-0.0709],\n",
      "        [-0.0612],\n",
      "        [-0.1050],\n",
      "        [-0.1054],\n",
      "        [-0.1039],\n",
      "        [-0.0754],\n",
      "        [-0.0704],\n",
      "        [-0.1135],\n",
      "        [-0.0724],\n",
      "        [-0.0736],\n",
      "        [-0.0727],\n",
      "        [-0.0975],\n",
      "        [-0.0815],\n",
      "        [-0.1091],\n",
      "        [-0.0639],\n",
      "        [-0.1014],\n",
      "        [-0.0801],\n",
      "        [-0.1020],\n",
      "        [-0.0732],\n",
      "        [-0.0699],\n",
      "        [-0.0553],\n",
      "        [-0.0990],\n",
      "        [-0.1019],\n",
      "        [-0.0767],\n",
      "        [-0.0722],\n",
      "        [-0.0741],\n",
      "        [-0.0872],\n",
      "        [-0.0837],\n",
      "        [-0.0743],\n",
      "        [-0.0918],\n",
      "        [-0.0690],\n",
      "        [-0.0637],\n",
      "        [-0.0822],\n",
      "        [-0.0839],\n",
      "        [-0.0729],\n",
      "        [-0.0686],\n",
      "        [-0.0952],\n",
      "        [-0.0974],\n",
      "        [-0.0970],\n",
      "        [-0.0673],\n",
      "        [-0.0998],\n",
      "        [-0.1001],\n",
      "        [-0.0764],\n",
      "        [-0.0865],\n",
      "        [-0.0770],\n",
      "        [-0.0969],\n",
      "        [-0.1017],\n",
      "        [-0.0868],\n",
      "        [-0.0454],\n",
      "        [-0.0788],\n",
      "        [-0.0594],\n",
      "        [-0.1080],\n",
      "        [-0.1045],\n",
      "        [-0.0699],\n",
      "        [-0.0695],\n",
      "        [-0.0818],\n",
      "        [-0.0452],\n",
      "        [-0.0805],\n",
      "        [-0.0948],\n",
      "        [-0.0621],\n",
      "        [-0.0924],\n",
      "        [-0.1041],\n",
      "        [-0.0799],\n",
      "        [-0.0887],\n",
      "        [-0.0918],\n",
      "        [-0.0833],\n",
      "        [-0.0689],\n",
      "        [-0.0635],\n",
      "        [-0.0645],\n",
      "        [-0.0771],\n",
      "        [-0.0643],\n",
      "        [-0.0808],\n",
      "        [-0.0820],\n",
      "        [-0.1042],\n",
      "        [-0.0861],\n",
      "        [-0.0755],\n",
      "        [-0.0812],\n",
      "        [-0.1005],\n",
      "        [-0.0709],\n",
      "        [-0.0617],\n",
      "        [-0.0868],\n",
      "        [-0.0795]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.Tensor(X_test.values)\n",
    "pred_y_test = CNET.predict(X_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "052180b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0555],\n",
      "        [0.0562],\n",
      "        [0.0568],\n",
      "        [0.0699],\n",
      "        [0.0684],\n",
      "        [0.0575],\n",
      "        [0.0563],\n",
      "        [0.0556],\n",
      "        [0.0707],\n",
      "        [0.0575],\n",
      "        [0.0557],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0560],\n",
      "        [0.0564],\n",
      "        [0.0560],\n",
      "        [0.0616],\n",
      "        [0.0563],\n",
      "        [0.0609],\n",
      "        [0.0655],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0558],\n",
      "        [0.0574],\n",
      "        [0.0590],\n",
      "        [0.0561],\n",
      "        [0.0558],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0602],\n",
      "        [0.0586],\n",
      "        [0.0565],\n",
      "        [0.0714],\n",
      "        [0.0250],\n",
      "        [0.0621],\n",
      "        [0.0556],\n",
      "        [0.0566],\n",
      "        [0.0622],\n",
      "        [0.0564],\n",
      "        [0.0558],\n",
      "        [0.0661],\n",
      "        [0.0560],\n",
      "        [0.0560],\n",
      "        [0.0556],\n",
      "        [0.0562],\n",
      "        [0.0616],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0611],\n",
      "        [0.0588],\n",
      "        [0.0597],\n",
      "        [0.0587],\n",
      "        [0.0557],\n",
      "        [0.0668],\n",
      "        [0.0705],\n",
      "        [0.0558],\n",
      "        [0.0573],\n",
      "        [0.0561],\n",
      "        [0.0745],\n",
      "        [0.0768],\n",
      "        [0.0601],\n",
      "        [0.0560],\n",
      "        [0.0598],\n",
      "        [0.0557],\n",
      "        [0.0720],\n",
      "        [0.0559],\n",
      "        [0.0626],\n",
      "        [0.0771],\n",
      "        [0.0566],\n",
      "        [0.0556],\n",
      "        [0.0563],\n",
      "        [0.0673],\n",
      "        [0.0694],\n",
      "        [0.0559],\n",
      "        [0.0552],\n",
      "        [0.0611],\n",
      "        [0.0566],\n",
      "        [0.0555],\n",
      "        [0.0597],\n",
      "        [0.0661],\n",
      "        [0.0701],\n",
      "        [0.0557],\n",
      "        [0.0557],\n",
      "        [0.0820],\n",
      "        [0.0683],\n",
      "        [0.0570],\n",
      "        [0.0873],\n",
      "        [0.0562],\n",
      "        [0.0565],\n",
      "        [0.0558],\n",
      "        [0.0551],\n",
      "        [0.0692],\n",
      "        [0.0561],\n",
      "        [0.0598],\n",
      "        [0.0558],\n",
      "        [0.0567],\n",
      "        [0.0554],\n",
      "        [0.0565],\n",
      "        [0.0615],\n",
      "        [0.0562],\n",
      "        [0.0560],\n",
      "        [0.0584],\n",
      "        [0.0697],\n",
      "        [0.0615],\n",
      "        [0.0632],\n",
      "        [0.0605],\n",
      "        [0.0600],\n",
      "        [0.0556],\n",
      "        [0.0785],\n",
      "        [0.0560],\n",
      "        [0.0795],\n",
      "        [0.0585],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0685],\n",
      "        [0.0554],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.0555],\n",
      "        [0.0919],\n",
      "        [0.0559],\n",
      "        [0.0712],\n",
      "        [0.0555],\n",
      "        [0.0554],\n",
      "        [0.0641],\n",
      "        [0.0627],\n",
      "        [0.0558],\n",
      "        [0.0556],\n",
      "        [0.0558],\n",
      "        [0.0559],\n",
      "        [0.0563],\n",
      "        [0.1138],\n",
      "        [0.0587],\n",
      "        [0.0579],\n",
      "        [0.0557],\n",
      "        [0.0706],\n",
      "        [0.0569],\n",
      "        [0.0557],\n",
      "        [0.0559],\n",
      "        [0.0558],\n",
      "        [0.0555],\n",
      "        [0.0559],\n",
      "        [0.0697],\n",
      "        [0.0564],\n",
      "        [0.0566],\n",
      "        [0.0558],\n",
      "        [0.0663],\n",
      "        [0.0555],\n",
      "        [0.0569],\n",
      "        [0.0553],\n",
      "        [0.0565],\n",
      "        [0.0815],\n",
      "        [0.0556],\n",
      "        [0.0766],\n",
      "        [0.0600],\n",
      "        [0.0701],\n",
      "        [0.0712],\n",
      "        [0.0561],\n",
      "        [0.0565],\n",
      "        [0.0686],\n",
      "        [0.0681],\n",
      "        [0.0556],\n",
      "        [0.0715],\n",
      "        [0.0558],\n",
      "        [0.0560],\n",
      "        [0.1097],\n",
      "        [0.0607],\n",
      "        [0.0586],\n",
      "        [0.0564],\n",
      "        [0.0555],\n",
      "        [0.0561],\n",
      "        [0.0654],\n",
      "        [0.0555],\n",
      "        [0.0560],\n",
      "        [0.0563],\n",
      "        [0.0608],\n",
      "        [0.0563],\n",
      "        [0.0565],\n",
      "        [0.0563],\n",
      "        [0.0860],\n",
      "        [0.0595],\n",
      "        [0.1062],\n",
      "        [0.0557],\n",
      "        [0.0561],\n",
      "        [0.0786],\n",
      "        [0.0562],\n",
      "        [0.0561],\n",
      "        [0.0796],\n",
      "        [0.0656],\n",
      "        [0.0568],\n",
      "        [0.0564],\n",
      "        [0.0557],\n",
      "        [0.0587],\n",
      "        [0.0561],\n",
      "        [0.0564],\n",
      "        [0.0561]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X1_test = torch.Tensor(X1_test.values)\n",
    "pred_y_test = RNET.predict(X1_test)\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856f713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f73cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316d6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23089968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af90136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a25ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa8d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963271e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eb133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac47b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
