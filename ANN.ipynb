{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1987f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE_regression(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea16fc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuralNet (Regression)\n",
    "class RegressionNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        pred_x = self.layer1(X_test)\n",
    "        \n",
    "        return {\"Predarray\" :pred_x}\n",
    "\n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))\n",
    "                \n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d62eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NuralNet (Classification)\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, X_train, hiddenlayer, node, Ouputnode):\n",
    "        super().__init__() #nn.Module의 __init__속성 및 메소드를 불러옴\n",
    "        self.X_train = X_train\n",
    "        self.hiddenlayer = hiddenlayer\n",
    "        self.node = node\n",
    "        self.Ouputnode = Ouputnode\n",
    "        ordered_dict = OrderedDict()\n",
    "        ordered_dict['Linear1'] = nn.Linear(X_train.size(1) , node)\n",
    "        ordered_dict['relu1'] = nn.ReLU()\n",
    "        for i in range(2 , hiddenlayer+2 ):\n",
    "            ordered_dict['Linear{}'.format(i)] = nn.Linear(node, node)\n",
    "            ordered_dict['relu{}'.format(i)] = nn.ReLU()\n",
    "        ordered_dict['Linear{}'.format(hiddenlayer+2)] = nn.Linear(node, Ouputnode)\n",
    "        self.layer1  = nn.Sequential(ordered_dict)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        pred_x = self.layer1(X_test)\n",
    "        \n",
    "        return {\"Predarray\" :pred_x}\n",
    "\n",
    "    \n",
    "    def fit(self,epochs,loader, criterion, optimizer):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            for step, (x, label) in enumerate(loader):\n",
    "                optimizer.zero_grad()  # optimizer의 매개변수를 0으로 만듬\n",
    "                y_pred = self.layer1(x)\n",
    "\n",
    "                loss = criterion(y_pred, label)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"{}epoch // loss ={}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b25f3beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNet(X_train, y_train, X_test,y_test, hiddenlayer, node, Ouputnode, epochs):\n",
    "    '''\n",
    "    \n",
    "        @Input \n",
    "            X_train : type : array\n",
    "            y_train : type : array\n",
    "            X_test : type : array\n",
    "            hiddenlayer : type : int\n",
    "            node : type : int\n",
    "            Ouputnode : type : int\n",
    "            epochs : type : int\n",
    "            \n",
    "        @Output\n",
    "            pred_y_test : type : array\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    \n",
    "    # 학습을 위한 데이터 전처리 \n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    #신경망 생성하기\n",
    "    model = ClassificationNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "    \n",
    "    \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"CNet.pt\")\n",
    "    \n",
    "    #테스트 데이터로 예측 결과 반환\n",
    "    pred_y_test = model.predict(X_test)\n",
    "    print(pred_y_test)\n",
    "    pred_y_test_tensor=pred_y_test['Predarray']\n",
    "    print(pred_y_test_tensor)\n",
    "    #파이토치 텐서를 넘파이 어레이로 전환\n",
    "    pred_y_test_tensor = pred_y_test_tensor.detach().numpy()\n",
    "    \n",
    "      # calculate AUC of model\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred_y_test_tensor)\n",
    "    auc = roc_auc_score(y_test, pred_y_test_tensor)\n",
    "      \n",
    "    return  {\"auc_score\": auc, \"fpr\":fpr, \"tpr\":tpr}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c71270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNet(X_train, y_train, X_test, y_test , hiddenlayer, node, Ouputnode, epochs):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "        @Input \n",
    "            X_train : type : array\n",
    "            y_train : type : array\n",
    "            X_test : type : array\n",
    "            hiddenlayer : type : int\n",
    "            node : type : int\n",
    "            Ouputnode : type : int\n",
    "            epochs : type : int\n",
    "            \n",
    "        @Output\n",
    "            pred_y_test : type : array\n",
    "            \n",
    "    '''\n",
    "    \n",
    "    # 데이터를 파이토치 텐서로 변경\n",
    "    X = torch.Tensor(X_train.values)\n",
    "    Y = torch.Tensor(y_train.values)\n",
    "    X_test = torch.Tensor(X_test.values)\n",
    "    \n",
    "    # 학습을 위한 데이터 전처리 \n",
    "    dataset = TensorDataset(X, Y)\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # 신경망 생성하기\n",
    "    model = RegressionNet(X, hiddenlayer, node, Ouputnode)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.fit(epochs,loader, criterion, optimizer)\n",
    "            \n",
    "    #학습되 모델 저장\n",
    "    torch.save(model, \"RNet.pt\")\n",
    "    \n",
    "    #테스트 데이터로 예측 결과 반환\n",
    "    pred_y_test = model.predict(X_test)\n",
    "    pred_y_test_tensor = pred_y_test['Predarray'] \n",
    "    #파이토치 텐서를 넘파이 어레이로 전환\n",
    "    pred_y_test = pred_y_test.detach().numpy()\n",
    "    \n",
    "    MSE = mean_squared_error(y_test, pred_y_test)  # MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\n",
    "    \n",
    "    # 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAPE = MAPE_regression(y_test, pred_y_test)\n",
    "    R_squared = r2_score(y_test, pred_y_test)\n",
    "    return {'pred_y' : pred_y_test, 'RMSE' : RMSE, 'MAPE' : MAPE, \"R_squared\" : R_squared}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6ec865d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model load\n",
    "\n",
    "def ANN_model_loader(pickleFile, tsdat) :\n",
    "    \"\"\"\n",
    "    저장한 모델을 로드한 후, 로드한 모델과 데이터를 활용해 분석 결과 리턴\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : ?\n",
    "        로드한 모델\n",
    "    tsdat : array\n",
    "        예측 데이터\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    모델 리턴과 동일\n",
    "\n",
    "    \"\"\"\n",
    "    model = torch.load(pickleFile)  \n",
    "    X = torch.Tensor(tsdat.values)\n",
    "    pred = model.predict(X)\n",
    "    pred = pred['Predarray']\n",
    "    pred = pred.detach().numpy()\n",
    "    \n",
    "    \n",
    "    return  pred \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "08163130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ab_te.csv\")\n",
    "df2 = pd.read_csv(\"RMS_bearing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "53543fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1.iloc[:,[0, 1, 2, 3]]\n",
    "y = df1.iloc[:,[4]]\n",
    "x1 = df2.iloc[:,[0,1,2]]\n",
    "y1 = df2.iloc[:,[3]]\n",
    "\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=33)\n",
    "\n",
    "X1_train,X1_test, y1_train, y1_test = train_test_split(x1,y1, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e8308379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch // loss =-0.0\n",
      "{'Predarray': tensor([[-0.4317],\n",
      "        [-0.5106],\n",
      "        [-0.5007],\n",
      "        [-0.5086],\n",
      "        [-0.4814],\n",
      "        [-0.4757],\n",
      "        [-0.4785],\n",
      "        [-0.5348],\n",
      "        [-0.6448],\n",
      "        [-0.5165],\n",
      "        [-0.4891],\n",
      "        [-0.6492],\n",
      "        [-0.6250],\n",
      "        [-0.4872],\n",
      "        [-0.4969],\n",
      "        [-0.5269],\n",
      "        [-0.5597],\n",
      "        [-0.4945],\n",
      "        [-0.4983],\n",
      "        [-0.5240],\n",
      "        [-0.4544],\n",
      "        [-0.4870],\n",
      "        [-0.5340],\n",
      "        [-0.4593],\n",
      "        [-0.5463],\n",
      "        [-0.5106],\n",
      "        [-0.5900],\n",
      "        [-0.5268],\n",
      "        [-0.6246],\n",
      "        [-0.5116],\n",
      "        [-0.4773],\n",
      "        [-0.5393],\n",
      "        [-0.4965],\n",
      "        [-0.4788],\n",
      "        [-0.6392],\n",
      "        [-0.4845],\n",
      "        [-0.5137],\n",
      "        [-0.6335],\n",
      "        [-0.5255],\n",
      "        [-0.5123],\n",
      "        [-0.6584],\n",
      "        [-0.5119],\n",
      "        [-0.4583],\n",
      "        [-0.4928],\n",
      "        [-0.6693],\n",
      "        [-0.5044],\n",
      "        [-0.4800],\n",
      "        [-0.5839],\n",
      "        [-0.5247],\n",
      "        [-0.4904],\n",
      "        [-0.4688],\n",
      "        [-0.5046],\n",
      "        [-0.5485],\n",
      "        [-0.5192],\n",
      "        [-0.4867],\n",
      "        [-0.4671],\n",
      "        [-0.4917],\n",
      "        [-0.5148],\n",
      "        [-0.5800],\n",
      "        [-0.5117],\n",
      "        [-0.5340],\n",
      "        [-0.4803],\n",
      "        [-0.4379],\n",
      "        [-0.5047],\n",
      "        [-0.4846],\n",
      "        [-0.4845],\n",
      "        [-0.5862],\n",
      "        [-0.4844],\n",
      "        [-0.5045],\n",
      "        [-0.4815],\n",
      "        [-0.5178],\n",
      "        [-0.6413],\n",
      "        [-0.5407],\n",
      "        [-0.5463],\n",
      "        [-0.5231],\n",
      "        [-0.4498],\n",
      "        [-0.5411],\n",
      "        [-0.6079],\n",
      "        [-0.5055],\n",
      "        [-0.5032],\n",
      "        [-0.5050],\n",
      "        [-0.6433],\n",
      "        [-0.6443],\n",
      "        [-0.4959],\n",
      "        [-0.5084],\n",
      "        [-0.4957],\n",
      "        [-0.5105],\n",
      "        [-0.5416],\n",
      "        [-0.5643],\n",
      "        [-0.4505],\n",
      "        [-0.5107],\n",
      "        [-0.5922],\n",
      "        [-0.5196],\n",
      "        [-0.4672],\n",
      "        [-0.4733],\n",
      "        [-0.4827],\n",
      "        [-0.4953],\n",
      "        [-0.4716],\n",
      "        [-0.5999],\n",
      "        [-0.6021],\n",
      "        [-0.4922],\n",
      "        [-0.5932],\n",
      "        [-0.4785],\n",
      "        [-0.5424],\n",
      "        [-0.5136],\n",
      "        [-0.5004],\n",
      "        [-0.4843],\n",
      "        [-0.5463],\n",
      "        [-0.4977],\n",
      "        [-0.5165],\n",
      "        [-0.5434],\n",
      "        [-0.5103],\n",
      "        [-0.5465],\n",
      "        [-0.5369],\n",
      "        [-0.4971],\n",
      "        [-0.5473],\n",
      "        [-0.5847],\n",
      "        [-0.5135],\n",
      "        [-0.5613],\n",
      "        [-0.5383],\n",
      "        [-0.5154],\n",
      "        [-0.4860],\n",
      "        [-0.4657],\n",
      "        [-0.5739],\n",
      "        [-0.5400],\n",
      "        [-0.5043],\n",
      "        [-0.4719],\n",
      "        [-0.4348],\n",
      "        [-0.5527],\n",
      "        [-0.5055],\n",
      "        [-0.5497],\n",
      "        [-0.6075],\n",
      "        [-0.4976],\n",
      "        [-0.4481],\n",
      "        [-0.5049],\n",
      "        [-0.5620],\n",
      "        [-0.5721],\n",
      "        [-0.5227],\n",
      "        [-0.4905],\n",
      "        [-0.4989],\n",
      "        [-0.5265],\n",
      "        [-0.4840],\n",
      "        [-0.5683],\n",
      "        [-0.5021],\n",
      "        [-0.5412],\n",
      "        [-0.4576],\n",
      "        [-0.4471],\n",
      "        [-0.5264],\n",
      "        [-0.5067],\n",
      "        [-0.5451],\n",
      "        [-0.5268],\n",
      "        [-0.5055],\n",
      "        [-0.4964],\n",
      "        [-0.4835],\n",
      "        [-0.5612],\n",
      "        [-0.6220],\n",
      "        [-0.4825],\n",
      "        [-0.5325],\n",
      "        [-0.4646],\n",
      "        [-0.6490],\n",
      "        [-0.4794],\n",
      "        [-0.5195],\n",
      "        [-0.4817],\n",
      "        [-0.6390],\n",
      "        [-0.5268],\n",
      "        [-0.5062],\n",
      "        [-0.6288],\n",
      "        [-0.5025],\n",
      "        [-0.5455],\n",
      "        [-0.5758],\n",
      "        [-0.4867],\n",
      "        [-0.4969],\n",
      "        [-0.5981],\n",
      "        [-0.4938],\n",
      "        [-0.5501],\n",
      "        [-0.4888],\n",
      "        [-0.4965],\n",
      "        [-0.4990],\n",
      "        [-0.5957],\n",
      "        [-0.4706],\n",
      "        [-0.4859],\n",
      "        [-0.4952],\n",
      "        [-0.4843],\n",
      "        [-0.6112],\n",
      "        [-0.4819],\n",
      "        [-0.4818],\n",
      "        [-0.5512],\n",
      "        [-0.5178],\n",
      "        [-0.5205],\n",
      "        [-0.5566],\n",
      "        [-0.5430],\n",
      "        [-0.4996],\n",
      "        [-0.6136],\n",
      "        [-0.5890],\n",
      "        [-0.4539],\n",
      "        [-0.4893],\n",
      "        [-0.4783],\n",
      "        [-0.4966],\n",
      "        [-0.5015],\n",
      "        [-0.5005],\n",
      "        [-0.4887],\n",
      "        [-0.4923],\n",
      "        [-0.5686],\n",
      "        [-0.4866],\n",
      "        [-0.5470],\n",
      "        [-0.5429],\n",
      "        [-0.7473],\n",
      "        [-0.4838],\n",
      "        [-0.5463],\n",
      "        [-0.5409],\n",
      "        [-0.4684],\n",
      "        [-0.6190],\n",
      "        [-0.5147],\n",
      "        [-0.5027],\n",
      "        [-0.7012],\n",
      "        [-0.5537],\n",
      "        [-0.4726],\n",
      "        [-0.5086],\n",
      "        [-0.4872],\n",
      "        [-0.4882],\n",
      "        [-0.5318],\n",
      "        [-0.4841],\n",
      "        [-0.4762],\n",
      "        [-0.4408],\n",
      "        [-0.5768],\n",
      "        [-0.5131],\n",
      "        [-0.5070],\n",
      "        [-0.5226],\n",
      "        [-0.5409],\n",
      "        [-0.5398],\n",
      "        [-0.5571],\n",
      "        [-0.4696],\n",
      "        [-0.4917],\n",
      "        [-0.6380],\n",
      "        [-0.5918],\n",
      "        [-0.4506],\n",
      "        [-0.5089],\n",
      "        [-0.5574],\n",
      "        [-0.5019],\n",
      "        [-0.5113]], grad_fn=<AddmmBackward0>)}\n",
      "tensor([[-0.4317],\n",
      "        [-0.5106],\n",
      "        [-0.5007],\n",
      "        [-0.5086],\n",
      "        [-0.4814],\n",
      "        [-0.4757],\n",
      "        [-0.4785],\n",
      "        [-0.5348],\n",
      "        [-0.6448],\n",
      "        [-0.5165],\n",
      "        [-0.4891],\n",
      "        [-0.6492],\n",
      "        [-0.6250],\n",
      "        [-0.4872],\n",
      "        [-0.4969],\n",
      "        [-0.5269],\n",
      "        [-0.5597],\n",
      "        [-0.4945],\n",
      "        [-0.4983],\n",
      "        [-0.5240],\n",
      "        [-0.4544],\n",
      "        [-0.4870],\n",
      "        [-0.5340],\n",
      "        [-0.4593],\n",
      "        [-0.5463],\n",
      "        [-0.5106],\n",
      "        [-0.5900],\n",
      "        [-0.5268],\n",
      "        [-0.6246],\n",
      "        [-0.5116],\n",
      "        [-0.4773],\n",
      "        [-0.5393],\n",
      "        [-0.4965],\n",
      "        [-0.4788],\n",
      "        [-0.6392],\n",
      "        [-0.4845],\n",
      "        [-0.5137],\n",
      "        [-0.6335],\n",
      "        [-0.5255],\n",
      "        [-0.5123],\n",
      "        [-0.6584],\n",
      "        [-0.5119],\n",
      "        [-0.4583],\n",
      "        [-0.4928],\n",
      "        [-0.6693],\n",
      "        [-0.5044],\n",
      "        [-0.4800],\n",
      "        [-0.5839],\n",
      "        [-0.5247],\n",
      "        [-0.4904],\n",
      "        [-0.4688],\n",
      "        [-0.5046],\n",
      "        [-0.5485],\n",
      "        [-0.5192],\n",
      "        [-0.4867],\n",
      "        [-0.4671],\n",
      "        [-0.4917],\n",
      "        [-0.5148],\n",
      "        [-0.5800],\n",
      "        [-0.5117],\n",
      "        [-0.5340],\n",
      "        [-0.4803],\n",
      "        [-0.4379],\n",
      "        [-0.5047],\n",
      "        [-0.4846],\n",
      "        [-0.4845],\n",
      "        [-0.5862],\n",
      "        [-0.4844],\n",
      "        [-0.5045],\n",
      "        [-0.4815],\n",
      "        [-0.5178],\n",
      "        [-0.6413],\n",
      "        [-0.5407],\n",
      "        [-0.5463],\n",
      "        [-0.5231],\n",
      "        [-0.4498],\n",
      "        [-0.5411],\n",
      "        [-0.6079],\n",
      "        [-0.5055],\n",
      "        [-0.5032],\n",
      "        [-0.5050],\n",
      "        [-0.6433],\n",
      "        [-0.6443],\n",
      "        [-0.4959],\n",
      "        [-0.5084],\n",
      "        [-0.4957],\n",
      "        [-0.5105],\n",
      "        [-0.5416],\n",
      "        [-0.5643],\n",
      "        [-0.4505],\n",
      "        [-0.5107],\n",
      "        [-0.5922],\n",
      "        [-0.5196],\n",
      "        [-0.4672],\n",
      "        [-0.4733],\n",
      "        [-0.4827],\n",
      "        [-0.4953],\n",
      "        [-0.4716],\n",
      "        [-0.5999],\n",
      "        [-0.6021],\n",
      "        [-0.4922],\n",
      "        [-0.5932],\n",
      "        [-0.4785],\n",
      "        [-0.5424],\n",
      "        [-0.5136],\n",
      "        [-0.5004],\n",
      "        [-0.4843],\n",
      "        [-0.5463],\n",
      "        [-0.4977],\n",
      "        [-0.5165],\n",
      "        [-0.5434],\n",
      "        [-0.5103],\n",
      "        [-0.5465],\n",
      "        [-0.5369],\n",
      "        [-0.4971],\n",
      "        [-0.5473],\n",
      "        [-0.5847],\n",
      "        [-0.5135],\n",
      "        [-0.5613],\n",
      "        [-0.5383],\n",
      "        [-0.5154],\n",
      "        [-0.4860],\n",
      "        [-0.4657],\n",
      "        [-0.5739],\n",
      "        [-0.5400],\n",
      "        [-0.5043],\n",
      "        [-0.4719],\n",
      "        [-0.4348],\n",
      "        [-0.5527],\n",
      "        [-0.5055],\n",
      "        [-0.5497],\n",
      "        [-0.6075],\n",
      "        [-0.4976],\n",
      "        [-0.4481],\n",
      "        [-0.5049],\n",
      "        [-0.5620],\n",
      "        [-0.5721],\n",
      "        [-0.5227],\n",
      "        [-0.4905],\n",
      "        [-0.4989],\n",
      "        [-0.5265],\n",
      "        [-0.4840],\n",
      "        [-0.5683],\n",
      "        [-0.5021],\n",
      "        [-0.5412],\n",
      "        [-0.4576],\n",
      "        [-0.4471],\n",
      "        [-0.5264],\n",
      "        [-0.5067],\n",
      "        [-0.5451],\n",
      "        [-0.5268],\n",
      "        [-0.5055],\n",
      "        [-0.4964],\n",
      "        [-0.4835],\n",
      "        [-0.5612],\n",
      "        [-0.6220],\n",
      "        [-0.4825],\n",
      "        [-0.5325],\n",
      "        [-0.4646],\n",
      "        [-0.6490],\n",
      "        [-0.4794],\n",
      "        [-0.5195],\n",
      "        [-0.4817],\n",
      "        [-0.6390],\n",
      "        [-0.5268],\n",
      "        [-0.5062],\n",
      "        [-0.6288],\n",
      "        [-0.5025],\n",
      "        [-0.5455],\n",
      "        [-0.5758],\n",
      "        [-0.4867],\n",
      "        [-0.4969],\n",
      "        [-0.5981],\n",
      "        [-0.4938],\n",
      "        [-0.5501],\n",
      "        [-0.4888],\n",
      "        [-0.4965],\n",
      "        [-0.4990],\n",
      "        [-0.5957],\n",
      "        [-0.4706],\n",
      "        [-0.4859],\n",
      "        [-0.4952],\n",
      "        [-0.4843],\n",
      "        [-0.6112],\n",
      "        [-0.4819],\n",
      "        [-0.4818],\n",
      "        [-0.5512],\n",
      "        [-0.5178],\n",
      "        [-0.5205],\n",
      "        [-0.5566],\n",
      "        [-0.5430],\n",
      "        [-0.4996],\n",
      "        [-0.6136],\n",
      "        [-0.5890],\n",
      "        [-0.4539],\n",
      "        [-0.4893],\n",
      "        [-0.4783],\n",
      "        [-0.4966],\n",
      "        [-0.5015],\n",
      "        [-0.5005],\n",
      "        [-0.4887],\n",
      "        [-0.4923],\n",
      "        [-0.5686],\n",
      "        [-0.4866],\n",
      "        [-0.5470],\n",
      "        [-0.5429],\n",
      "        [-0.7473],\n",
      "        [-0.4838],\n",
      "        [-0.5463],\n",
      "        [-0.5409],\n",
      "        [-0.4684],\n",
      "        [-0.6190],\n",
      "        [-0.5147],\n",
      "        [-0.5027],\n",
      "        [-0.7012],\n",
      "        [-0.5537],\n",
      "        [-0.4726],\n",
      "        [-0.5086],\n",
      "        [-0.4872],\n",
      "        [-0.4882],\n",
      "        [-0.5318],\n",
      "        [-0.4841],\n",
      "        [-0.4762],\n",
      "        [-0.4408],\n",
      "        [-0.5768],\n",
      "        [-0.5131],\n",
      "        [-0.5070],\n",
      "        [-0.5226],\n",
      "        [-0.5409],\n",
      "        [-0.5398],\n",
      "        [-0.5571],\n",
      "        [-0.4696],\n",
      "        [-0.4917],\n",
      "        [-0.6380],\n",
      "        [-0.5918],\n",
      "        [-0.4506],\n",
      "        [-0.5089],\n",
      "        [-0.5574],\n",
      "        [-0.5019],\n",
      "        [-0.5113]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pred_y2_test= CNet(X_train, y_train, X_test,y_test, 2, 5, 1, 10)\n",
    "\n",
    "\n",
    "\n",
    "#CNet(X_train, y_train, X_test,y_test, hiddenlayer, node, Ouputnode, epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "01ff45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auc_score': 0.6908168935815504, 'fpr': array([0.        , 0.        , 0.        , 0.00819672, 0.00819672,\n",
      "       0.01639344, 0.01639344, 0.02459016, 0.02459016, 0.03278689,\n",
      "       0.03278689, 0.04098361, 0.04098361, 0.04918033, 0.04918033,\n",
      "       0.05737705, 0.05737705, 0.08196721, 0.08196721, 0.10655738,\n",
      "       0.10655738, 0.1147541 , 0.1147541 , 0.13114754, 0.13114754,\n",
      "       0.13934426, 0.13934426, 0.14754098, 0.14754098, 0.1557377 ,\n",
      "       0.1557377 , 0.18032787, 0.18032787, 0.20491803, 0.20491803,\n",
      "       0.22131148, 0.22131148, 0.2295082 , 0.2295082 , 0.23770492,\n",
      "       0.23770492, 0.24590164, 0.24590164, 0.2704918 , 0.2704918 ,\n",
      "       0.27868852, 0.27868852, 0.28688525, 0.28688525, 0.29508197,\n",
      "       0.29508197, 0.31147541, 0.31147541, 0.32786885, 0.32786885,\n",
      "       0.33606557, 0.33606557, 0.36065574, 0.36065574, 0.36885246,\n",
      "       0.36885246, 0.37704918, 0.37704918, 0.3852459 , 0.3852459 ,\n",
      "       0.41803279, 0.41803279, 0.45081967, 0.45081967, 0.46721311,\n",
      "       0.46721311, 0.48360656, 0.48360656, 0.49180328, 0.49180328,\n",
      "       0.5       , 0.5       , 0.50819672, 0.50819672, 0.51639344,\n",
      "       0.51639344, 0.53278689, 0.53278689, 0.54098361, 0.54098361,\n",
      "       0.56557377, 0.56557377, 0.58196721, 0.58196721, 0.60655738,\n",
      "       0.60655738, 0.6147541 , 0.6147541 , 0.64754098, 0.71311475,\n",
      "       0.71311475, 0.7295082 , 0.7295082 , 0.79508197, 0.79508197,\n",
      "       0.80327869, 0.80327869, 0.82786885, 0.82786885, 0.8852459 ,\n",
      "       0.8852459 , 0.90163934, 0.90163934, 0.90983607, 0.90983607,\n",
      "       0.91803279, 0.91803279, 0.94262295, 0.94262295, 0.95081967,\n",
      "       0.95081967, 1.        ]), 'tpr': array([0.        , 0.00847458, 0.01694915, 0.01694915, 0.07627119,\n",
      "       0.07627119, 0.08474576, 0.08474576, 0.10169492, 0.10169492,\n",
      "       0.11016949, 0.11016949, 0.13559322, 0.13559322, 0.15254237,\n",
      "       0.15254237, 0.22881356, 0.22881356, 0.23728814, 0.23728814,\n",
      "       0.26271186, 0.26271186, 0.33050847, 0.33050847, 0.34745763,\n",
      "       0.34745763, 0.37288136, 0.37288136, 0.38135593, 0.38135593,\n",
      "       0.38983051, 0.38983051, 0.43220339, 0.43220339, 0.46610169,\n",
      "       0.46610169, 0.48305085, 0.48305085, 0.51694915, 0.51694915,\n",
      "       0.52542373, 0.52542373, 0.55084746, 0.55084746, 0.56779661,\n",
      "       0.56779661, 0.58474576, 0.58474576, 0.59322034, 0.59322034,\n",
      "       0.60169492, 0.60169492, 0.62711864, 0.62711864, 0.63559322,\n",
      "       0.63559322, 0.65254237, 0.65254237, 0.66101695, 0.66101695,\n",
      "       0.66949153, 0.66949153, 0.6779661 , 0.6779661 , 0.69491525,\n",
      "       0.69491525, 0.72881356, 0.72881356, 0.73728814, 0.73728814,\n",
      "       0.74576271, 0.74576271, 0.75423729, 0.75423729, 0.76271186,\n",
      "       0.76271186, 0.77118644, 0.77118644, 0.79661017, 0.79661017,\n",
      "       0.80508475, 0.80508475, 0.81355932, 0.81355932, 0.8220339 ,\n",
      "       0.8220339 , 0.83898305, 0.83898305, 0.84745763, 0.84745763,\n",
      "       0.8559322 , 0.8559322 , 0.86440678, 0.86440678, 0.86440678,\n",
      "       0.87288136, 0.87288136, 0.88135593, 0.88135593, 0.89830508,\n",
      "       0.89830508, 0.92372881, 0.92372881, 0.93220339, 0.93220339,\n",
      "       0.94067797, 0.94067797, 0.95762712, 0.95762712, 0.96610169,\n",
      "       0.96610169, 0.97457627, 0.97457627, 0.99152542, 0.99152542,\n",
      "       1.        , 1.        ])}\n"
     ]
    }
   ],
   "source": [
    "print(pred_y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18d5423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch // loss =1.4847279089735821e-05\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_y1_test \u001b[38;5;241m=\u001b[39m \u001b[43mRNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36mRNet\u001b[0;34m(X_train, y_train, X_test, y_test, hiddenlayer, node, Ouputnode, epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m pred_y_test_tensor \u001b[38;5;241m=\u001b[39m pred_y_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredarray\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#파이토치 텐서를 넘파이 어레이로 전환\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m pred_y_test \u001b[38;5;241m=\u001b[39m \u001b[43mpred_y_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     43\u001b[0m MSE \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, pred_y_test)  \u001b[38;5;66;03m# MSE 값은 출력하지 않아도 됩니다. RMSE를 구하기 위한 절차입니다.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 출력 대상입니다. 성능지표로써 3가지값이 출력되게 됩니다.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "pred_y1_test = RNet(X1_train, y1_train, X1_test, y1_test, 2, 5, 1, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667426f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNET = torch.load(\"RNet.pt\")\n",
    "RNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c155a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (layer1): Sequential(\n",
       "    (Linear1): Linear(in_features=4, out_features=5, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (Linear2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (Linear3): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (relu3): ReLU()\n",
       "    (Linear4): Linear(in_features=5, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNET = torch.load(\"CNet.pt\")\n",
    "CNET.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "34b069c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ANN_model_loader(\"RNet.pt\", X1_test) \n",
    "pred2 = ANN_model_loader(\"CNet.pt\", X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bcea5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.431688  ]\n",
      " [-0.51064414]\n",
      " [-0.5007413 ]\n",
      " [-0.5085681 ]\n",
      " [-0.48137718]\n",
      " [-0.47569665]\n",
      " [-0.478481  ]\n",
      " [-0.53478116]\n",
      " [-0.64481914]\n",
      " [-0.5164831 ]\n",
      " [-0.48913002]\n",
      " [-0.64923143]\n",
      " [-0.624988  ]\n",
      " [-0.48717114]\n",
      " [-0.49688876]\n",
      " [-0.5269459 ]\n",
      " [-0.5596838 ]\n",
      " [-0.49450058]\n",
      " [-0.4982707 ]\n",
      " [-0.5240153 ]\n",
      " [-0.4544198 ]\n",
      " [-0.4870419 ]\n",
      " [-0.533968  ]\n",
      " [-0.45932218]\n",
      " [-0.5463269 ]\n",
      " [-0.5105579 ]\n",
      " [-0.5900216 ]\n",
      " [-0.5267583 ]\n",
      " [-0.62464166]\n",
      " [-0.5115942 ]\n",
      " [-0.47728044]\n",
      " [-0.5393333 ]\n",
      " [-0.4965279 ]\n",
      " [-0.47877356]\n",
      " [-0.6391877 ]\n",
      " [-0.4844889 ]\n",
      " [-0.5136964 ]\n",
      " [-0.6335081 ]\n",
      " [-0.5255253 ]\n",
      " [-0.5122563 ]\n",
      " [-0.65844977]\n",
      " [-0.51188   ]\n",
      " [-0.45833248]\n",
      " [-0.49279922]\n",
      " [-0.6692928 ]\n",
      " [-0.5044303 ]\n",
      " [-0.4799586 ]\n",
      " [-0.5838595 ]\n",
      " [-0.52473974]\n",
      " [-0.4903763 ]\n",
      " [-0.4688428 ]\n",
      " [-0.50462615]\n",
      " [-0.5484752 ]\n",
      " [-0.519225  ]\n",
      " [-0.4866736 ]\n",
      " [-0.4671256 ]\n",
      " [-0.49169773]\n",
      " [-0.5148054 ]\n",
      " [-0.58003795]\n",
      " [-0.5117135 ]\n",
      " [-0.5340092 ]\n",
      " [-0.48028278]\n",
      " [-0.43794397]\n",
      " [-0.50472754]\n",
      " [-0.48461336]\n",
      " [-0.48448232]\n",
      " [-0.58622396]\n",
      " [-0.48438042]\n",
      " [-0.50450176]\n",
      " [-0.48145294]\n",
      " [-0.5178369 ]\n",
      " [-0.6412872 ]\n",
      " [-0.54069436]\n",
      " [-0.5463269 ]\n",
      " [-0.52305144]\n",
      " [-0.4497779 ]\n",
      " [-0.54114634]\n",
      " [-0.6078935 ]\n",
      " [-0.5055019 ]\n",
      " [-0.5031891 ]\n",
      " [-0.50504994]\n",
      " [-0.6432576 ]\n",
      " [-0.6442573 ]\n",
      " [-0.4958558 ]\n",
      " [-0.50836605]\n",
      " [-0.49568918]\n",
      " [-0.510505  ]\n",
      " [-0.5416299 ]\n",
      " [-0.56434226]\n",
      " [-0.4505301 ]\n",
      " [-0.5106883 ]\n",
      " [-0.5922264 ]\n",
      " [-0.51962554]\n",
      " [-0.4671706 ]\n",
      " [-0.47325775]\n",
      " [-0.48267567]\n",
      " [-0.49527842]\n",
      " [-0.47163033]\n",
      " [-0.59993625]\n",
      " [-0.60211635]\n",
      " [-0.4922294 ]\n",
      " [-0.59317875]\n",
      " [-0.47845274]\n",
      " [-0.54244375]\n",
      " [-0.51363194]\n",
      " [-0.5003635 ]\n",
      " [-0.48427022]\n",
      " [-0.5463269 ]\n",
      " [-0.49772364]\n",
      " [-0.5165106 ]\n",
      " [-0.54338217]\n",
      " [-0.510292  ]\n",
      " [-0.54647404]\n",
      " [-0.5369222 ]\n",
      " [-0.49706584]\n",
      " [-0.54728186]\n",
      " [-0.5846914 ]\n",
      " [-0.51351756]\n",
      " [-0.56129366]\n",
      " [-0.53827566]\n",
      " [-0.51537645]\n",
      " [-0.48600805]\n",
      " [-0.46571565]\n",
      " [-0.57392025]\n",
      " [-0.5400331 ]\n",
      " [-0.5042764 ]\n",
      " [-0.47185755]\n",
      " [-0.43475425]\n",
      " [-0.55271   ]\n",
      " [-0.5055188 ]\n",
      " [-0.5496734 ]\n",
      " [-0.6074625 ]\n",
      " [-0.49761397]\n",
      " [-0.44808888]\n",
      " [-0.5048841 ]\n",
      " [-0.56199443]\n",
      " [-0.57206637]\n",
      " [-0.52270246]\n",
      " [-0.49049217]\n",
      " [-0.4988757 ]\n",
      " [-0.52648914]\n",
      " [-0.48395228]\n",
      " [-0.56832683]\n",
      " [-0.5020741 ]\n",
      " [-0.5412164 ]\n",
      " [-0.45758432]\n",
      " [-0.4470898 ]\n",
      " [-0.5263758 ]\n",
      " [-0.506707  ]\n",
      " [-0.5451323 ]\n",
      " [-0.5268109 ]\n",
      " [-0.5055489 ]\n",
      " [-0.49639484]\n",
      " [-0.4834574 ]\n",
      " [-0.5612216 ]\n",
      " [-0.6220236 ]\n",
      " [-0.48249525]\n",
      " [-0.53253305]\n",
      " [-0.46460682]\n",
      " [-0.64896655]\n",
      " [-0.47942019]\n",
      " [-0.51946646]\n",
      " [-0.48171383]\n",
      " [-0.63898444]\n",
      " [-0.5267812 ]\n",
      " [-0.5061837 ]\n",
      " [-0.6287681 ]\n",
      " [-0.5025282 ]\n",
      " [-0.54550505]\n",
      " [-0.5758084 ]\n",
      " [-0.48673594]\n",
      " [-0.4969049 ]\n",
      " [-0.5981246 ]\n",
      " [-0.4937556 ]\n",
      " [-0.550056  ]\n",
      " [-0.48875982]\n",
      " [-0.4965409 ]\n",
      " [-0.49896836]\n",
      " [-0.5956527 ]\n",
      " [-0.47061956]\n",
      " [-0.48590988]\n",
      " [-0.49524075]\n",
      " [-0.48425698]\n",
      " [-0.6111895 ]\n",
      " [-0.48186204]\n",
      " [-0.48180348]\n",
      " [-0.55116326]\n",
      " [-0.51782966]\n",
      " [-0.52050644]\n",
      " [-0.5566405 ]\n",
      " [-0.5429945 ]\n",
      " [-0.4995901 ]\n",
      " [-0.6136193 ]\n",
      " [-0.58904874]\n",
      " [-0.45385098]\n",
      " [-0.4893038 ]\n",
      " [-0.47834027]\n",
      " [-0.4966293 ]\n",
      " [-0.5014564 ]\n",
      " [-0.5004723 ]\n",
      " [-0.48873246]\n",
      " [-0.49229515]\n",
      " [-0.56857777]\n",
      " [-0.4865694 ]\n",
      " [-0.5470097 ]\n",
      " [-0.54294366]\n",
      " [-0.7472512 ]\n",
      " [-0.48382646]\n",
      " [-0.5463269 ]\n",
      " [-0.5409068 ]\n",
      " [-0.4684266 ]\n",
      " [-0.6189925 ]\n",
      " [-0.51467746]\n",
      " [-0.5026504 ]\n",
      " [-0.70120436]\n",
      " [-0.55372196]\n",
      " [-0.47260946]\n",
      " [-0.50861347]\n",
      " [-0.48722234]\n",
      " [-0.48822147]\n",
      " [-0.53175807]\n",
      " [-0.48414713]\n",
      " [-0.47624832]\n",
      " [-0.44078577]\n",
      " [-0.5767945 ]\n",
      " [-0.5130501 ]\n",
      " [-0.50695044]\n",
      " [-0.52258414]\n",
      " [-0.54094094]\n",
      " [-0.5398394 ]\n",
      " [-0.5571258 ]\n",
      " [-0.46963176]\n",
      " [-0.49172384]\n",
      " [-0.63798696]\n",
      " [-0.5918109 ]\n",
      " [-0.45056903]\n",
      " [-0.508922  ]\n",
      " [-0.55743635]\n",
      " [-0.50187284]\n",
      " [-0.5112895 ]]\n"
     ]
    }
   ],
   "source": [
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a0326758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1365],\n",
      "        [0.1475],\n",
      "        [0.1428],\n",
      "        [0.1460],\n",
      "        [0.1430],\n",
      "        [0.1421],\n",
      "        [0.1432],\n",
      "        [0.1492],\n",
      "        [0.1723],\n",
      "        [0.1490],\n",
      "        [0.1479],\n",
      "        [0.1490],\n",
      "        [0.1564],\n",
      "        [0.1437],\n",
      "        [0.1466],\n",
      "        [0.1459],\n",
      "        [0.1458],\n",
      "        [0.1421],\n",
      "        [0.1448],\n",
      "        [0.1443],\n",
      "        [0.1547],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1587],\n",
      "        [0.1534],\n",
      "        [0.1437],\n",
      "        [0.1555],\n",
      "        [0.1509],\n",
      "        [0.1654],\n",
      "        [0.1452],\n",
      "        [0.1421],\n",
      "        [0.1512],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1639],\n",
      "        [0.1421],\n",
      "        [0.1440],\n",
      "        [0.1512],\n",
      "        [0.1490],\n",
      "        [0.1480],\n",
      "        [0.1583],\n",
      "        [0.1493],\n",
      "        [0.1421],\n",
      "        [0.1430],\n",
      "        [0.1467],\n",
      "        [0.1436],\n",
      "        [0.1421],\n",
      "        [0.1563],\n",
      "        [0.1430],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1484],\n",
      "        [0.1472],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1493],\n",
      "        [0.1513],\n",
      "        [0.1436],\n",
      "        [0.1492],\n",
      "        [0.1421],\n",
      "        [0.1443],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1514],\n",
      "        [0.1443],\n",
      "        [0.1437],\n",
      "        [0.1428],\n",
      "        [0.1422],\n",
      "        [0.1801],\n",
      "        [0.1480],\n",
      "        [0.1494],\n",
      "        [0.1435],\n",
      "        [0.1495],\n",
      "        [0.1483],\n",
      "        [0.1518],\n",
      "        [0.1467],\n",
      "        [0.1446],\n",
      "        [0.1421],\n",
      "        [0.1583],\n",
      "        [0.1518],\n",
      "        [0.1421],\n",
      "        [0.1503],\n",
      "        [0.1458],\n",
      "        [0.1452],\n",
      "        [0.1491],\n",
      "        [0.1466],\n",
      "        [0.1421],\n",
      "        [0.1443],\n",
      "        [0.1512],\n",
      "        [0.1500],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1433],\n",
      "        [0.1425],\n",
      "        [0.1421],\n",
      "        [0.1502],\n",
      "        [0.1421],\n",
      "        [0.1442],\n",
      "        [0.1476],\n",
      "        [0.1425],\n",
      "        [0.1513],\n",
      "        [0.1421],\n",
      "        [0.1481],\n",
      "        [0.1421],\n",
      "        [0.1496],\n",
      "        [0.1457],\n",
      "        [0.1447],\n",
      "        [0.1466],\n",
      "        [0.1446],\n",
      "        [0.1514],\n",
      "        [0.1515],\n",
      "        [0.1421],\n",
      "        [0.1489],\n",
      "        [0.1520],\n",
      "        [0.1456],\n",
      "        [0.1490],\n",
      "        [0.1485],\n",
      "        [0.1488],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1518],\n",
      "        [0.1485],\n",
      "        [0.1486],\n",
      "        [0.1487],\n",
      "        [0.1407],\n",
      "        [0.1490],\n",
      "        [0.1484],\n",
      "        [0.1506],\n",
      "        [0.1542],\n",
      "        [0.1461],\n",
      "        [0.1421],\n",
      "        [0.1433],\n",
      "        [0.1499],\n",
      "        [0.1447],\n",
      "        [0.1446],\n",
      "        [0.1425],\n",
      "        [0.1434],\n",
      "        [0.1473],\n",
      "        [0.1421],\n",
      "        [0.1493],\n",
      "        [0.1434],\n",
      "        [0.1509],\n",
      "        [0.1634],\n",
      "        [0.1504],\n",
      "        [0.1488],\n",
      "        [0.1421],\n",
      "        [0.1564],\n",
      "        [0.1445],\n",
      "        [0.1479],\n",
      "        [0.1432],\n",
      "        [0.1421],\n",
      "        [0.1690],\n",
      "        [0.1526],\n",
      "        [0.1425],\n",
      "        [0.1447],\n",
      "        [0.1421],\n",
      "        [0.1496],\n",
      "        [0.1424],\n",
      "        [0.1449],\n",
      "        [0.1422],\n",
      "        [0.1511],\n",
      "        [0.1423],\n",
      "        [0.1752],\n",
      "        [0.1521],\n",
      "        [0.1448],\n",
      "        [0.1476],\n",
      "        [0.1516],\n",
      "        [0.1421],\n",
      "        [0.1463],\n",
      "        [0.1560],\n",
      "        [0.1433],\n",
      "        [0.1485],\n",
      "        [0.1424],\n",
      "        [0.1421],\n",
      "        [0.1424],\n",
      "        [0.1509],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1504],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1500],\n",
      "        [0.1459],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1467],\n",
      "        [0.1434],\n",
      "        [0.1502],\n",
      "        [0.1447],\n",
      "        [0.1421],\n",
      "        [0.1636],\n",
      "        [0.1421],\n",
      "        [0.1432],\n",
      "        [0.1431],\n",
      "        [0.1468],\n",
      "        [0.1427],\n",
      "        [0.1643],\n",
      "        [0.1421],\n",
      "        [0.1455],\n",
      "        [0.1502],\n",
      "        [0.1487],\n",
      "        [0.1757],\n",
      "        [0.1421],\n",
      "        [0.1491],\n",
      "        [0.1491],\n",
      "        [0.1427],\n",
      "        [0.1572],\n",
      "        [0.1439],\n",
      "        [0.1479],\n",
      "        [0.1744],\n",
      "        [0.1477],\n",
      "        [0.1421],\n",
      "        [0.1476],\n",
      "        [0.1456],\n",
      "        [0.1425],\n",
      "        [0.1493],\n",
      "        [0.1421],\n",
      "        [0.1421],\n",
      "        [0.1410],\n",
      "        [0.1515],\n",
      "        [0.1421],\n",
      "        [0.1451],\n",
      "        [0.1479],\n",
      "        [0.1483],\n",
      "        [0.1469],\n",
      "        [0.1476],\n",
      "        [0.1421],\n",
      "        [0.1445],\n",
      "        [0.1421],\n",
      "        [0.1513],\n",
      "        [0.1418],\n",
      "        [0.1456],\n",
      "        [0.1513],\n",
      "        [0.1467],\n",
      "        [0.1481]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.Tensor(X_test.values)\n",
    "pred_y_test = CNET.predict(X_test)\n",
    "pred_y_test= pred_y_test['Predarray']\n",
    "print(pred_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5af90136",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [126]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mpred_y_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "x = pred_y_test.items()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "304f3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7d9a25ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.80602336e+00  7.63494074e-01 -9.77539539e-01  1.22985256e+00]\n",
      " [ 2.88958907e+00 -9.56516191e-02  7.65324593e-01 -9.44870412e-02]\n",
      " [-2.81016648e-01  1.17189419e+00  6.46489739e-01  1.38244259e+00]\n",
      " [-1.38564634e+00  1.03286839e+00  9.64946330e-01  1.18931937e+00]\n",
      " [-3.84974442e-02 -1.02425289e+00 -2.86061287e-01  1.26748371e+00]\n",
      " [ 9.19930637e-01  8.03538024e-01  6.98452473e-01  1.89077008e+00]\n",
      " [ 1.52581644e+00  1.26883960e+00  1.14634144e+00  1.60621655e+00]\n",
      " [ 8.93510342e-01 -7.05286086e-01  1.13732183e+00  1.85925201e-01]\n",
      " [-7.45542467e-01  1.20459169e-01  1.77639592e+00 -1.88747442e+00]\n",
      " [ 1.36878800e+00  1.86112916e+00  1.96436131e+00  9.19935822e-01]\n",
      " [ 2.69998002e+00  5.97405493e-01  1.54226673e+00  6.48979664e-01]\n",
      " [-8.96511495e-01 -6.84065670e-02 -1.07213056e+00 -1.85259724e+00]\n",
      " [-1.97832420e-01  1.87706971e+00  1.81530488e+00 -4.25111383e-01]\n",
      " [ 1.40733492e+00  8.21575403e-01  2.77685165e-01  3.94608140e-01]\n",
      " [ 1.38334978e+00 -1.24526672e-01  9.10424232e-01  6.20447576e-01]\n",
      " [-1.71543211e-01  6.91975415e-01  3.66911441e-02 -1.74816892e-01]\n",
      " [-6.86651707e-01  1.43566579e-01 -3.20241392e-01 -4.07077760e-01]\n",
      " [-2.52801389e-01  2.18979061e-01 -7.38499224e-01  6.42536223e-01]\n",
      " [ 1.40342069e+00 -5.78122020e-01  4.07882124e-01  4.76658642e-01]\n",
      " [ 6.91806316e-01  1.76665902e+00 -1.57457441e-01 -3.26479167e-01]\n",
      " [ 1.19080925e+00  3.97284091e-01  7.53618002e-01  2.80766058e+00]\n",
      " [ 3.90806012e-02  6.04038835e-01  1.56270251e-01  1.61365438e+00]\n",
      " [-9.35298860e-01  5.02597392e-01 -1.30100906e+00  4.70453411e-01]\n",
      " [-3.21475007e-02 -3.38304609e-01  3.51339430e-01  3.22393394e+00]\n",
      " [-1.02450550e+00 -1.72002757e+00  1.15266991e+00 -9.42222595e-01]\n",
      " [-3.93172950e-01 -4.13686305e-01 -2.70908445e-01  1.94377035e-01]\n",
      " [-3.02103847e-01 -2.33460534e-02  1.83910513e+00 -4.57861125e-01]\n",
      " [ 3.92413467e-01  2.11782718e+00  2.36851907e+00  8.55646610e-01]\n",
      " [ 4.84465778e-01 -4.55895007e-01  1.79812562e+00 -1.33667743e+00]\n",
      " [ 1.56319320e+00 -1.15237379e+00 -1.50510609e+00 -1.05137026e+00]\n",
      " [ 7.01231956e-01  8.11074004e-02  8.06263983e-01  1.91536856e+00]\n",
      " [-1.07575321e+00  2.39254212e+00  1.84392202e+00  4.04377639e-01]\n",
      " [-5.43356203e-02  3.81881297e-01  2.83428848e-01  1.19540358e+00]\n",
      " [ 7.12299287e-01  7.38774538e-01 -2.03050911e-01  1.17062223e+00]\n",
      " [ 5.27384102e-01  1.10618544e+00  1.81068587e+00 -1.02852070e+00]\n",
      " [ 1.00417721e+00  1.65585220e+00 -3.25741768e-02  9.20687318e-01]\n",
      " [ 8.10571238e-02 -8.92664611e-01 -3.84078801e-01  1.35933280e-01]\n",
      " [-1.01257928e-01  1.89653575e+00  5.39610803e-01 -1.31154895e+00]\n",
      " [ 8.25852394e-01 -4.01066333e-01  1.47355807e+00  6.04827046e-01]\n",
      " [ 3.40632153e+00  1.27060056e+00  1.23744500e+00  7.87297487e-02]\n",
      " [-2.30334252e-01  2.98170336e-02  2.95696944e-01 -2.25997233e+00]\n",
      " [-7.95461237e-01  1.85782444e+00  1.44657195e+00  6.31223559e-01]\n",
      " [ 1.15871370e+00  2.70998567e-01 -6.87861264e-01  1.40984118e+00]\n",
      " [ 7.10952580e-01  2.07935214e+00  9.20739412e-01  1.38924170e+00]\n",
      " [-2.39497757e+00  9.92106274e-02 -1.38347507e+00 -1.08273280e+00]\n",
      " [-5.17369807e-01  1.19272721e+00  5.21303535e-01  1.04237282e+00]\n",
      " [ 1.11442184e+00  2.17955017e+00 -1.64980799e-01  1.10562146e+00]\n",
      " [ 2.57594496e-01  4.15109038e-01  2.44238281e+00  2.34082580e-01]\n",
      " [-1.82674086e+00  2.93219596e-01 -6.71914294e-02  9.76419270e-01]\n",
      " [-1.79103345e-01 -6.74322024e-02  1.19958170e-01  1.43156767e+00]\n",
      " [ 1.08784807e+00  1.36357260e+00 -6.75081074e-01  1.15879858e+00]\n",
      " [-6.22002900e-01  1.25958586e+00  2.02364612e+00  1.62255287e+00]\n",
      " [-8.71875808e-02 -2.34921312e+00  5.27634025e-01  4.70991999e-01]\n",
      " [-1.71530831e+00  2.92870522e-01 -5.55779159e-01  1.35396314e+00]\n",
      " [ 2.21391380e-01  7.37673581e-01  9.87910450e-01  2.16150475e+00]\n",
      " [ 8.76855776e-02  4.98728424e-01 -1.37193310e+00  1.46879530e+00]\n",
      " [ 4.76819202e-02  2.12868285e+00 -7.75575876e-01  9.74349082e-01]\n",
      " [ 6.17947519e-01  7.02276051e-01  1.59824276e+00  6.28885448e-01]\n",
      " [ 2.15422079e-01  1.94229674e+00  1.35281384e+00 -4.27361965e-01]\n",
      " [-6.58297166e-02  9.16425109e-01 -1.90829307e-01  6.65651411e-02]\n",
      " [ 6.18713439e-01 -6.39919698e-01  5.26146770e-01 -4.87584352e-01]\n",
      " [-3.04796100e-01  1.79588759e+00  6.03175938e-01  2.96672153e+00]\n",
      " [ 2.02586889e+00 -1.15383828e+00 -1.11696255e+00  1.87314105e+00]\n",
      " [-1.37603074e-01  9.01404381e-01 -1.83743149e-01  5.54383516e-01]\n",
      " [ 4.41531986e-01  1.06904829e+00  1.58182383e-01  1.47691941e+00]\n",
      " [-3.57659757e-01  2.03445411e+00 -1.08664560e+00  1.52610648e+00]\n",
      " [-1.00030077e+00 -1.45491570e-01  6.73419833e-01 -1.14088213e+00]\n",
      " [ 6.54803813e-01 -3.30645502e-01  1.03517354e+00  1.56875062e+00]\n",
      " [ 1.23846245e+00  7.39127815e-01 -5.47689080e-01 -6.53925598e-01]\n",
      " [ 1.63898849e+00  6.77850068e-01 -1.45161303e-03  2.35315353e-01]\n",
      " [-9.81239796e-01 -8.66173208e-02 -1.20288229e+00  7.11660504e-01]\n",
      " [ 6.13741994e-01  1.00910909e-01  3.46940541e+00 -6.97062671e-01]\n",
      " [-3.46176922e-02 -1.48182857e+00  2.67985582e-01 -1.45508766e-01]\n",
      " [-1.83095789e+00  4.38349068e-01  1.50648510e+00  6.43762469e-01]\n",
      " [ 1.01505029e+00  1.48729575e+00 -6.01547599e-01 -7.18635261e-01]\n",
      " [ 1.86521542e+00 -2.78303415e-01  4.98691618e-01  2.02410460e+00]\n",
      " [-4.23428208e-01  5.68091571e-01  5.57428539e-01 -4.56391312e-02]\n",
      " [ 5.83596587e-01  1.25061500e+00  1.50998902e+00 -4.18289036e-01]\n",
      " [ 8.49133879e-02  4.76942882e-02  1.04085922e+00  9.81211483e-01]\n",
      " [-6.11286908e-02  1.18102781e-01  5.87728202e-01  9.55547512e-01]\n",
      " [-3.91681433e-01  2.47613415e-01 -1.72040892e+00  6.26459062e-01]\n",
      " [ 8.84497702e-01  7.86993265e-01  1.07734156e+00 -1.58000100e+00]\n",
      " [-2.61278033e-01  8.59709620e-01  3.02099347e-01 -1.70515656e+00]\n",
      " [ 3.99209261e-01  1.21084368e+00  3.63147944e-01  1.06238782e+00]\n",
      " [ 9.27509189e-01  1.33162069e+00  2.60394979e+00  1.27996051e+00]\n",
      " [ 5.43602347e-01  1.34997058e+00  1.80754387e+00  1.96444368e+00]\n",
      " [ 2.47738630e-01  1.11479986e+00  2.64734626e-01  1.47262141e-01]\n",
      " [ 1.09446239e+00 -9.75690424e-01  1.49315500e+00  5.28381348e-01]\n",
      " [-7.76087463e-01  3.50717694e-01 -2.18948126e-01 -4.96048421e-01]\n",
      " [ 2.21187520e+00 -8.20986331e-01 -7.94101536e-01  8.53183508e-01]\n",
      " [ 1.68561721e+00 -1.06813669e-01 -7.30277359e-01 -9.29542124e-01]\n",
      " [-8.08947444e-01 -3.03828508e-01  4.12739575e-01 -1.32684147e+00]\n",
      " [ 1.47521353e+00  1.67051947e+00  2.35994792e+00  1.00378823e+00]\n",
      " [ 8.80767763e-01 -7.12782502e-01 -4.91387755e-01  1.01703119e+00]\n",
      " [ 1.47496939e+00  1.23035872e+00  1.93544358e-01  1.18186343e+00]\n",
      " [ 1.20726609e+00  1.39867520e+00  1.30418074e+00  1.83984411e+00]\n",
      " [ 1.28547478e+00 -9.51308429e-01 -5.96342206e-01  8.35335776e-02]\n",
      " [ 1.51899487e-01  3.69772702e-01  2.74454728e-02  2.24000597e+00]\n",
      " [ 7.30550587e-02  1.10310197e+00  6.35257304e-01 -7.82785773e-01]\n",
      " [-8.02770019e-01  9.42951500e-01 -1.63149297e+00 -9.17910576e-01]\n",
      " [ 7.49778152e-01  7.61912167e-01  9.42048609e-01  1.27696133e+00]\n",
      " [-2.67765641e-01  7.14419544e-01 -3.15256357e-01 -1.00023818e+00]\n",
      " [ 1.32169664e+00  8.31545234e-01  7.97612607e-01  1.41540098e+00]\n",
      " [ 1.79200754e-01 -1.69738042e+00 -3.03396523e-01 -1.61280012e+00]\n",
      " [-1.34436023e+00  8.26696813e-01 -1.03005028e+00  1.50688374e+00]\n",
      " [ 5.28611720e-01  1.87691748e+00  1.79886091e+00  1.20252848e+00]\n",
      " [ 1.35032034e+00  8.12487483e-01 -2.73393810e-01  1.73122883e-01]\n",
      " [-3.66536885e-01 -2.58009702e-01  1.81320775e+00  7.29547501e-01]\n",
      " [ 6.55410945e-01  1.27308178e+00  1.58866501e+00  1.68825996e+00]\n",
      " [ 9.67799187e-01 -1.16581810e+00 -2.40051397e-03  1.74238443e-01]\n",
      " [-3.60551864e-01  1.15937614e+00 -1.69742957e-01 -6.25500619e-01]\n",
      " [-4.71661426e-02 -1.00406539e+00 -1.05717731e+00 -1.54850557e-01]\n",
      " [ 1.44678295e-01  1.90536305e-01  2.33491731e+00  5.99263728e-01]\n",
      " [ 7.13315248e-01 -1.64673340e+00  2.24040532e+00  1.55826584e-01]\n",
      " [ 4.98519301e-01  2.19584250e+00 -1.26238540e-01  5.51559985e-01]\n",
      " [-9.54360843e-01 -1.13288140e+00  5.06459534e-01 -2.75955558e-01]\n",
      " [ 1.79238334e-01 -3.68818343e-02  1.47603095e+00 -4.74652052e-01]\n",
      " [ 1.22402656e+00  5.11565387e-01 -1.48839265e-01 -6.01607502e-01]\n",
      " [-1.64507776e-01 -4.54070985e-01 -1.65781975e-01 -1.08532286e+00]\n",
      " [-3.64141501e-02 -1.04955423e+00  7.00380445e-01  1.34193692e-02]\n",
      " [-1.29570651e+00  1.11018562e+00  1.41330504e+00  9.25875306e-01]\n",
      " [ 5.93715310e-01  5.05025148e-01 -4.41581964e-01  6.10457897e-01]\n",
      " [ 7.50903189e-01  4.39372025e-02 -1.31434631e+00  8.17355871e-01]\n",
      " [ 1.38682961e+00  1.07725334e+00  2.09602189e+00  1.13253951e-01]\n",
      " [ 9.42864776e-01 -1.13681209e+00  7.60650575e-01  6.57692028e-04]\n",
      " [ 9.23225641e-01  1.20333421e+00  1.94162178e+00  1.15604472e+00]\n",
      " [ 1.90847707e+00 -6.68560743e-01  8.95460308e-01  1.46788847e+00]\n",
      " [ 1.23424542e+00  1.70857698e-01 -1.57197154e+00  2.63521290e+00]\n",
      " [-2.65525490e-01  5.22855282e-01  5.94661057e-01 -2.49874726e-01]\n",
      " [-9.89487529e-01  2.19962192e+00  1.35139787e+00  8.33218813e-01]\n",
      " [ 1.02421761e+00 -5.82444191e-01  8.84835601e-01 -6.67392194e-01]\n",
      " [ 1.50305247e+00  2.34854087e-01  1.16750419e+00 -1.22683752e+00]\n",
      " [ 1.15174961e+00  8.58470142e-01  7.36208558e-01  4.09539849e-01]\n",
      " [ 2.68103743e+00  1.67251348e+00 -1.31495285e+00  3.53088617e-01]\n",
      " [ 3.45466584e-01  2.29722905e+00  1.94507465e-01  3.72712016e-01]\n",
      " [-7.13424087e-01  7.54586756e-02  2.81660408e-01 -8.53395998e-01]\n",
      " [-1.33579969e+00 -5.15750885e-01 -1.11415887e+00 -3.52789015e-02]\n",
      " [-7.56744385e-01  7.51058310e-02  2.32983291e-01  6.14769936e-01]\n",
      " [-2.80296415e-01 -6.41773760e-01 -1.50224611e-01  1.09395468e+00]\n",
      " [-5.18834293e-01 -4.85674083e-01  5.53882718e-01  1.46193469e+00]\n",
      " [ 9.33945626e-02  4.47159372e-02  3.46650034e-01 -9.70039964e-02]\n",
      " [ 6.65349305e-01  4.38443184e-01  3.44334990e-01  1.27867997e+00]\n",
      " [-1.47861218e+00 -1.85032737e+00 -6.56682476e-02 -7.38453627e-01]\n",
      " [-8.22897136e-01  6.46628857e-01  1.01216757e+00  1.89612865e+00]\n",
      " [ 1.08675909e+00 -9.36863303e-01  1.28046155e+00 -3.60786468e-01]\n",
      " [ 9.84573424e-01  9.16214764e-01  1.20284641e+00  3.32690477e+00]\n",
      " [ 1.16356230e+00  3.29389006e-01  2.98495859e-01  2.87874293e+00]\n",
      " [ 1.58472145e+00 -7.38425791e-01  1.58074701e+00  6.83550477e-01]\n",
      " [ 1.51787019e+00  1.25937867e+00 -9.36693132e-01 -7.86507308e-01]\n",
      " [ 5.62492132e-01 -2.39544082e+00  1.37622625e-01  5.69237709e-01]\n",
      " [ 1.38346851e+00  2.21323013e+00  2.09516153e-01 -1.09283291e-01]\n",
      " [ 7.48119771e-01  1.05924046e+00  1.53724456e+00  1.01203525e+00]\n",
      " [-1.25389123e+00 -1.86987147e-01  2.54213661e-01  2.22934580e+00]\n",
      " [ 3.19875330e-01  1.97201061e+00  9.36601281e-01  2.48669195e+00]\n",
      " [ 8.93826246e-01 -2.91791129e+00  6.44789755e-01 -2.10891199e+00]\n",
      " [ 1.40899658e+00  7.67802477e-01  1.56364691e+00 -6.55550718e-01]\n",
      " [ 1.56967258e+00  1.77283800e+00  6.76690042e-01  1.07779408e+00]\n",
      " [ 1.46872187e+00  3.15395427e+00  5.26243627e-01  1.09320275e-01]\n",
      " [ 6.64285064e-01  1.58161342e+00 -1.23933971e+00  1.43021560e+00]\n",
      " [-2.45330453e+00  4.08567339e-01 -4.34032679e-01 -1.35668766e+00]\n",
      " [ 1.40935063e+00 -8.69301379e-01  4.54335034e-01  1.23310578e+00]\n",
      " [ 6.42803386e-02 -1.52682853e+00  9.12948370e-01  1.34756052e+00]\n",
      " [ 2.52171564e+00 -4.44985241e-01 -8.86007071e-01 -5.30406833e-01]\n",
      " [ 6.17120326e-01  1.04941678e+00  1.35073930e-01 -1.82983100e+00]\n",
      " [-8.34645212e-01  1.50961190e-01 -6.23735607e-01  1.19641557e-01]\n",
      " [ 1.90323925e+00 -2.08690310e+00  1.03197825e+00  1.72343159e+00]\n",
      " [-4.20498818e-01  1.27313101e+00  6.75642908e-01 -1.39518762e+00]\n",
      " [ 7.38766253e-01  1.53543770e+00  6.93952978e-01  6.76511645e-01]\n",
      " [ 5.73851705e-01  1.01593864e+00 -2.65976097e-02 -8.71995270e-01]\n",
      " [ 1.36222422e+00 -8.78682435e-02  1.03935933e+00 -9.30751204e-01]\n",
      " [ 2.65661508e-01  1.38165832e-01 -1.03920770e+00  3.15820545e-01]\n",
      " [ 1.64450693e+00 -1.34724748e+00  7.66088009e-01  1.17224467e+00]\n",
      " [-3.84184331e-01  6.31083310e-01  2.04331636e+00 -1.96718886e-01]\n",
      " [ 7.44258225e-01 -3.44964802e-01 -3.66661400e-02  3.78077865e-01]\n",
      " [-5.87662578e-01 -1.72344267e-01  9.71428096e-01  3.97886455e-01]\n",
      " [ 8.95429552e-02 -8.62207353e-01 -1.83507085e-01  9.82611120e-01]\n",
      " [ 1.40348980e-02  7.29934275e-01 -3.06376070e-01  7.39371538e-01]\n",
      " [ 6.76013291e-01  1.65788007e+00  1.07356355e-01  5.12591779e-01]\n",
      " [-2.23963761e+00  1.23760080e+00  1.02522051e+00 -3.81611258e-01]\n",
      " [ 4.46933299e-01 -4.26310390e-01 -4.44966644e-01  1.41472721e+00]\n",
      " [ 8.78634632e-01 -4.00651544e-01 -3.67430627e-01  3.38204950e-01]\n",
      " [-1.35036200e-01  2.35619396e-01 -7.23336935e-01  4.98106986e-01]\n",
      " [ 2.99324036e-01  1.60333943e+00 -6.40728474e-02  1.59903598e+00]\n",
      " [ 2.23574594e-01  3.50268662e-01  9.45113376e-02 -1.48962998e+00]\n",
      " [-3.81683588e-01 -1.67659428e-02 -3.00243437e-01  1.80641079e+00]\n",
      " [ 7.34604657e-01  3.78788501e-01 -8.90837967e-01  3.19774330e-01]\n",
      " [ 1.72312236e+00  2.09159112e+00  1.52865016e+00 -4.19775844e-02]\n",
      " [ 5.28841019e-01 -2.89279938e-01 -1.75220426e-02 -2.52982259e-01]\n",
      " [-4.39209849e-01  6.21797919e-01 -7.32565820e-01 -2.79910248e-02]\n",
      " [-1.77654517e+00  7.79489338e-01 -1.46392417e+00  1.03685367e+00]\n",
      " [-5.73655367e-01 -8.90225172e-01 -5.09007215e-01 -3.61831725e-01]\n",
      " [ 1.09948575e+00  2.17806194e-02 -8.46001804e-01 -7.62967765e-01]\n",
      " [ 5.34012258e-01  6.42882168e-01  3.11533570e-01 -1.22033107e+00]\n",
      " [-1.50218475e+00 -4.40810770e-01 -7.45271921e-01 -7.43635297e-02]\n",
      " [ 2.31891584e+00  7.46464670e-01 -1.23422253e+00  1.95530653e-01]\n",
      " [ 4.97020632e-01 -7.36383498e-01  1.67315257e+00  2.13171029e+00]\n",
      " [ 1.20678949e+00  3.51341784e-01  1.08393893e-01  8.53510976e-01]\n",
      " [-1.00193667e+00  2.49145579e+00  6.58919334e-01  1.23432076e+00]\n",
      " [ 7.60100260e-02 -6.53647661e-01 -2.76107024e-02  6.09992802e-01]\n",
      " [ 8.62444639e-01 -3.90724689e-01  1.20451081e+00  1.10295296e+00]\n",
      " [ 1.17695248e+00  1.80131507e+00  7.30180562e-01  1.15472615e+00]\n",
      " [-3.30800056e-01 -1.13501392e-01  1.61452997e+00  2.66883230e+00]\n",
      " [-8.24718714e-01  3.70724201e-01 -1.91852283e+00 -3.81418198e-01]\n",
      " [ 7.59621084e-01 -1.77787110e-01  1.37538779e+00  1.65610409e+00]\n",
      " [ 9.94950458e-02 -2.31354618e+00  6.52992278e-02 -8.06316972e-01]\n",
      " [-5.07491410e-01 -1.32417881e+00  2.01775402e-01 -5.01929581e-01]\n",
      " [-2.20962620e+00  5.88047087e-01  1.45370197e+00 -2.48847866e+00]\n",
      " [-9.28104758e-01  6.40998423e-01  2.95589864e-01  2.89070940e+00]\n",
      " [-1.57372212e+00 -1.03387630e+00  1.28367925e+00  3.07147503e-01]\n",
      " [ 3.37100172e+00 -1.18809044e-01  1.22761559e+00 -2.36772880e-01]\n",
      " [ 1.28756928e+00 -1.06135952e+00 -1.14675009e+00  5.09565115e-01]\n",
      " [ 4.08127040e-01  8.00706863e-01  1.61764205e+00 -7.21467197e-01]\n",
      " [-1.19684100e+00  4.36575711e-01  2.11457059e-01  8.08155000e-01]\n",
      " [ 9.33817148e-01  1.35909486e+00  1.66991901e+00  1.10478580e+00]\n",
      " [-1.75059462e+00 -1.82408184e-01  1.45154905e+00 -2.47800350e+00]\n",
      " [-7.37954915e-01 -2.33737841e-01  4.46166724e-01  1.19345620e-01]\n",
      " [ 1.29904723e+00 -3.14334869e-01 -1.30588031e+00 -1.99714705e-01]\n",
      " [-6.62725627e-01  1.67269778e+00  9.81865466e-01  5.86349905e-01]\n",
      " [ 1.37295437e+00  8.66130114e-01  1.29384351e+00  1.26047421e+00]\n",
      " [ 1.76906312e+00 -5.66876292e-01 -3.79156679e-01  2.67651174e-02]\n",
      " [ 2.50532418e-01  6.19810462e-01  1.18138814e+00  2.29023248e-01]\n",
      " [ 4.62547630e-01  2.54937381e-01 -2.18537137e-01  9.66141284e-01]\n",
      " [-3.01709324e-02 -1.06183343e-01 -4.62799549e-01  1.62984538e+00]\n",
      " [ 1.66201127e+00  1.48215652e+00 -1.12962079e+00  2.05445385e+00]\n",
      " [-6.30291462e-01 -9.05198336e-01  4.02297258e-01 -1.43693686e+00]\n",
      " [ 8.82765353e-02  2.09868693e+00 -1.16774499e+00  1.46713421e-01]\n",
      " [-2.51167130e+00  2.00669003e+00  9.35044527e-01  1.49416006e+00]\n",
      " [ 7.06917226e-01  8.83728266e-01  5.96967399e-01 -1.59396052e-01]\n",
      " [ 3.57287258e-01  1.61796403e+00  4.29769427e-01 -4.97922689e-01]\n",
      " [-7.07341611e-01 -8.12801644e-02  6.14701390e-01  5.11926413e-01]\n",
      " [-5.07217824e-01 -3.49497557e-01  2.20539227e-01 -1.68806434e-01]\n",
      " [ 1.73303974e+00 -3.93467307e-01 -5.11865877e-02  7.14753747e-01]\n",
      " [ 9.95527327e-01  1.09718192e+00  1.02105319e+00  1.21251643e+00]\n",
      " [-5.30513763e-01  1.41372883e+00 -2.77894092e+00 -1.64242780e+00]\n",
      " [ 2.03634351e-01  1.48892747e-02  8.36449027e-01 -8.67117167e-01]\n",
      " [ 2.41660643e+00  2.68650115e-01 -4.84297313e-02  1.12640405e+00]\n",
      " [-1.70078818e-02  1.13046861e+00  5.63010335e-01  4.99575466e-01]\n",
      " [ 3.67020279e-01  2.21213508e+00  1.73788786e+00 -5.58829820e-03]\n",
      " [ 1.19152951e+00  8.40552211e-01  7.14796901e-01  2.15821400e-01]\n",
      " [ 9.80233073e-01  1.32690871e+00  1.33287179e+00  6.16985261e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa8d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d9a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747da4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963271e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304eb133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e9494c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d5792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac47b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98249f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
